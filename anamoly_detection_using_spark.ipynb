{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"C:\\\\Program Files\\\\Java\\\\jdk-21\"  # Update with your Java version\n",
    "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"\\\\bin;\" + os.environ[\"PATH\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession \n",
    "from pyspark.sql.functions import col,log1p,sqrt,expr, to_timestamp, skewness, kurtosis, lag, when\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('anamoly_detection_using_spark') \\\n",
    ".config(\"spark.driver.memory\", \"8g\") \\\n",
    ".config(\"spark.executor.memory\", \"8g\") \\\n",
    ".config(\"spark.sql.execution.arrow.enabled\", \"true\") \\\n",
    ".getOrCreate()\n",
    "# spark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")\n",
    "df= spark.read.csv('burke-gilman-trail-north-of-ne-70th-st-bike-and-ped-counter (4).csv',header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------------+---------+---------+----------+----------+\n",
      "|               Date|BGT North of NE 70th Total|Ped South|Ped North|Bike North|Bike South|\n",
      "+-------------------+--------------------------+---------+---------+----------+----------+\n",
      "|2014-01-01 00:00:00|                        15|        0|        2|         2|        11|\n",
      "|2014-01-01 01:00:00|                         9|        1|        0|         1|         7|\n",
      "|2014-01-01 02:00:00|                         9|        0|        0|         0|         9|\n",
      "|2014-01-01 03:00:00|                        19|        0|        0|         0|        19|\n",
      "|2014-01-01 04:00:00|                        19|        0|        0|         0|        19|\n",
      "|2014-01-01 05:00:00|                        14|        0|        0|         0|        14|\n",
      "|2014-01-01 06:00:00|                        10|        0|        1|         1|         8|\n",
      "|2014-01-01 07:00:00|                        10|        2|        3|         4|         1|\n",
      "|2014-01-01 08:00:00|                        27|       12|        6|         8|         1|\n",
      "|2014-01-01 09:00:00|                        29|        5|       14|         8|         2|\n",
      "|2014-01-01 10:00:00|                        70|       14|       16|        40|         0|\n",
      "|2014-01-01 11:00:00|                       107|       20|       39|        47|         1|\n",
      "|2014-01-01 12:00:00|                       126|       36|       31|        59|         0|\n",
      "|2014-01-01 13:00:00|                       102|       21|       16|        65|         0|\n",
      "|2014-01-01 14:00:00|                       115|       16|       20|        78|         1|\n",
      "|2014-01-01 15:00:00|                       100|       25|       17|        58|         0|\n",
      "|2014-01-01 16:00:00|                        50|       18|       15|        17|         0|\n",
      "|2014-01-01 17:00:00|                        18|        6|        3|         9|         0|\n",
      "|2014-01-01 18:00:00|                         3|        1|        1|         0|         1|\n",
      "|2014-01-01 19:00:00|                        16|        5|        3|         4|         4|\n",
      "+-------------------+--------------------------+---------+---------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = df.withColumn('Date', to_timestamp(col('Date')))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data type conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Ped South', 'Ped North', 'Bike South', 'Bike North']\n",
    "\n",
    "for col_name in columns:\n",
    "    df = df.withColumn(col_name,col(col_name).cast('double'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filling null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------------+---------+---------+----------+----------+\n",
      "|               Date|BGT North of NE 70th Total|Ped South|Ped North|Bike North|Bike South|\n",
      "+-------------------+--------------------------+---------+---------+----------+----------+\n",
      "|2014-01-01 00:00:00|                      15.0|      0.0|      2.0|       2.0|      11.0|\n",
      "|2014-01-01 01:00:00|                       9.0|      1.0|      0.0|       1.0|       7.0|\n",
      "|2014-01-01 02:00:00|                       9.0|      0.0|      0.0|       0.0|       9.0|\n",
      "|2014-01-01 03:00:00|                      19.0|      0.0|      0.0|       0.0|      19.0|\n",
      "|2014-01-01 04:00:00|                      19.0|      0.0|      0.0|       0.0|      19.0|\n",
      "|2014-01-01 05:00:00|                      14.0|      0.0|      0.0|       0.0|      14.0|\n",
      "|2014-01-01 06:00:00|                      10.0|      0.0|      1.0|       1.0|       8.0|\n",
      "|2014-01-01 07:00:00|                      10.0|      2.0|      3.0|       4.0|       1.0|\n",
      "|2014-01-01 08:00:00|                      27.0|     12.0|      6.0|       8.0|       1.0|\n",
      "|2014-01-01 09:00:00|                      29.0|      5.0|     14.0|       8.0|       2.0|\n",
      "+-------------------+--------------------------+---------+---------+----------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns = ['Ped South', 'Ped North', 'Bike South', 'Bike North']\n",
    "\n",
    "for col_name in columns:\n",
    "    median_value = df.approxQuantile(col_name,[0.5], 0.01)[0]\n",
    "    df = df.fillna({col_name:median_value})\n",
    "\n",
    "\n",
    "# Recalculate 'BGT North of NE 70th Total' as sum of other columns\n",
    "df = df.withColumn(\"BGT North of NE 70th Total\",\n",
    "                   col(\"Ped South\") + col(\"Ped North\") + col(\"Bike South\") + col(\"Bike North\"))\n",
    "\n",
    "\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------------+---------+---------+----------+----------+\n",
      "|               Date|BGT North of NE 70th Total|Ped South|Ped North|Bike North|Bike South|\n",
      "+-------------------+--------------------------+---------+---------+----------+----------+\n",
      "|2014-01-01 00:00:00|                      15.0|      0.0|      2.0|       2.0|      11.0|\n",
      "|2014-01-01 01:00:00|                       9.0|      1.0|      0.0|       1.0|       7.0|\n",
      "|2014-01-01 02:00:00|                       9.0|      0.0|      0.0|       0.0|       9.0|\n",
      "|2014-01-01 03:00:00|                      19.0|      0.0|      0.0|       0.0|      19.0|\n",
      "|2014-01-01 04:00:00|                      19.0|      0.0|      0.0|       0.0|      19.0|\n",
      "|2014-01-01 05:00:00|                      14.0|      0.0|      0.0|       0.0|      14.0|\n",
      "|2014-01-01 06:00:00|                      10.0|      0.0|      1.0|       1.0|       8.0|\n",
      "|2014-01-01 07:00:00|                      10.0|      2.0|      3.0|       4.0|       1.0|\n",
      "|2014-01-01 08:00:00|                      27.0|     12.0|      6.0|       8.0|       1.0|\n",
      "|2014-01-01 09:00:00|                      29.0|      5.0|     14.0|       8.0|       2.0|\n",
      "|2014-01-01 10:00:00|                      70.0|     14.0|     16.0|      40.0|       0.0|\n",
      "|2014-01-01 11:00:00|                     107.0|     20.0|     39.0|      47.0|       1.0|\n",
      "|2014-01-01 12:00:00|                     126.0|     36.0|     31.0|      59.0|       0.0|\n",
      "|2014-01-01 13:00:00|                     102.0|     21.0|     16.0|      65.0|       0.0|\n",
      "|2014-01-01 14:00:00|                     115.0|     16.0|     20.0|      78.0|       1.0|\n",
      "|2014-01-01 15:00:00|                     100.0|     25.0|     17.0|      58.0|       0.0|\n",
      "|2014-01-01 16:00:00|                      50.0|     18.0|     15.0|      17.0|       0.0|\n",
      "|2014-01-01 17:00:00|                      18.0|      6.0|      3.0|       9.0|       0.0|\n",
      "|2014-01-01 18:00:00|                       3.0|      1.0|      1.0|       0.0|       1.0|\n",
      "|2014-01-01 19:00:00|                      16.0|      5.0|      3.0|       4.0|       4.0|\n",
      "+-------------------+--------------------------+---------+---------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_spec = Window().orderBy('Date')\n",
    "#setting target feature\n",
    "df = df.withColumn(\"Anomaly\", when(col(\"BGT North of NE 70th Total\") >= 500, 1).otherwise(0))\n",
    "df = df.withColumn(\"Anomaly_3hr_Ahead\", lag(\"Anomaly\", -3).over(window_spec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------------+------------------+------------------+------------------+-----------------+--------------------+--------------------+\n",
      "|summary|BGT North of NE 70th Total|         Ped South|         Ped North|        Bike North|       Bike South|             Anomaly|   Anomaly_3hr_Ahead|\n",
      "+-------+--------------------------+------------------+------------------+------------------+-----------------+--------------------+--------------------+\n",
      "|  count|                     52584|             52584|             52584|             52584|            52584|               52584|               52581|\n",
      "|   mean|         71.81901338810285|19.641487905066178|  9.56891830214514|21.231268066331964|21.37733911455956|0.009432527004411988|0.009433065175633784|\n",
      "| stddev|        187.81586738317858|132.90530737258584|40.713128071069825|32.668014651585224|61.25083457766319|  0.0966629822127716|  0.0966657135118246|\n",
      "|    min|                       0.0|               0.0|               0.0|               0.0|              0.0|                   0|                   0|\n",
      "|    max|                   10493.0|            4054.0|            4095.0|             794.0|           8191.0|                   1|                   1|\n",
      "+-------+--------------------------+------------------+------------------+------------------+-----------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute Summary Statistics\n",
    "summary_stat = df.describe()\n",
    "summary_stat.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+------------------+----------------+-----------------+------------------+\n",
      "|BGT North of NE 70th Total|         Ped South|       Ped North|       Bike South|        Bike North|\n",
      "+--------------------------+------------------+----------------+-----------------+------------------+\n",
      "|        15.379001270982352|13.533858768190937|34.6978752720907|96.23681914118107|3.6588230632740046|\n",
      "+--------------------------+------------------+----------------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Compute Skewness & Kurtosis\n",
    "skewness_df  = df.select(\n",
    "    skewness(col(\"BGT North of NE 70th Total\")).alias(\"BGT North of NE 70th Total\"),\n",
    "    skewness(col('Ped South')).alias('Ped South'),\n",
    "    skewness(col('Ped North')).alias('Ped North'),\n",
    "    skewness(col('Bike South')).alias('Bike South'),\n",
    "    skewness(col('Bike North')).alias('Bike North'),\n",
    "    # kurtosis(col(\"BGT North of NE 70th Total\")).alias(\"kurtosis\")\n",
    ").show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+------------------+-----------------+------------------+-----------------+\n",
      "|BGT North of NE 70th Total|         Ped South|        Ped North|        Bike South|       Bike North|\n",
      "+--------------------------+------------------+-----------------+------------------+-----------------+\n",
      "|         470.2432004263731|210.74836960311225|2303.585144564282|12409.412551529564|36.69746248680579|\n",
      "+--------------------------+------------------+-----------------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute Kurtosis\n",
    "kurtosis_df = df.select(\n",
    "    kurtosis(col('BGT North of NE 70th Total')).alias('BGT North of NE 70th Total'),\n",
    "    kurtosis(col('Ped South')).alias('Ped South'),\n",
    "    kurtosis(col('Ped North')).alias('Ped North'),\n",
    "    kurtosis(col('Bike South')).alias('Bike South'),\n",
    "    kurtosis(col('Bike North')).alias('Bike North')\n",
    ").show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91.0\n"
     ]
    }
   ],
   "source": [
    "# using log transformation \n",
    "df = df.withColumn('BGT North of NE 70th Total', log1p(df['BGT North of NE 70th Total']))\n",
    "df = df.withColumn('Ped South', log1p(df['Ped South']))\n",
    "df = df.withColumn('Bike North', log1p(df['Bike North']))\n",
    "\n",
    "#using square root transformation\n",
    "df = df.withColumn('Ped North', sqrt(df['Ped North']))\n",
    "\n",
    "#using Winsorization transformation\n",
    "\n",
    "#compute percentile\n",
    "percentile_99 = df.approxQuantile('Bike South',[0.97],0.01)[0]\n",
    "print(percentile_99)\n",
    "# Apply capping (Winsorization)\n",
    "df = df.withColumn('Bike South', expr(f\"CASE WHEN `Bike South` > {float(percentile_99)} THEN {float(percentile_99)} ELSE `Bike South` END\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lag features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create lag feature\n",
    "df = df.withColumn('Lag_1_day',lag(\"BGT North of NE 70th Total\", 1).over(window_spec))\n",
    "df = df.withColumn('Lag_2_day',lag(\"BGT North of NE 70th Total\", 2).over(window_spec))\n",
    "df = df.withColumn('Lag_3_day',lag(\"BGT North of NE 70th Total\", 3).over(window_spec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------------+------------------+------------------+------------------+----------+-------+-----------------+------------------+------------------+------------------+\n",
      "|               Date|BGT North of NE 70th Total|         Ped South|         Ped North|        Bike North|Bike South|Anomaly|Anomaly_3hr_Ahead|         Lag_1_day|         Lag_2_day|         Lag_3_day|\n",
      "+-------------------+--------------------------+------------------+------------------+------------------+----------+-------+-----------------+------------------+------------------+------------------+\n",
      "|2014-01-01 00:00:00|         2.772588722239781|               0.0|1.4142135623730951|1.0986122886681096|      11.0|      0|                0|              NULL|              NULL|              NULL|\n",
      "|2014-01-01 01:00:00|         2.302585092994046|0.6931471805599453|               0.0|0.6931471805599453|       7.0|      0|                0| 2.772588722239781|              NULL|              NULL|\n",
      "|2014-01-01 02:00:00|         2.302585092994046|               0.0|               0.0|               0.0|       9.0|      0|                0| 2.302585092994046| 2.772588722239781|              NULL|\n",
      "|2014-01-01 03:00:00|         2.995732273553991|               0.0|               0.0|               0.0|      19.0|      0|                0| 2.302585092994046| 2.302585092994046| 2.772588722239781|\n",
      "|2014-01-01 04:00:00|         2.995732273553991|               0.0|               0.0|               0.0|      19.0|      0|                0| 2.995732273553991| 2.302585092994046| 2.302585092994046|\n",
      "|2014-01-01 05:00:00|          2.70805020110221|               0.0|               0.0|               0.0|      14.0|      0|                0| 2.995732273553991| 2.995732273553991| 2.302585092994046|\n",
      "|2014-01-01 06:00:00|        2.3978952727983707|               0.0|               1.0|0.6931471805599453|       8.0|      0|                0|  2.70805020110221| 2.995732273553991| 2.995732273553991|\n",
      "|2014-01-01 07:00:00|        2.3978952727983707|1.0986122886681096|1.7320508075688772|1.6094379124341003|       1.0|      0|                0|2.3978952727983707|  2.70805020110221| 2.995732273553991|\n",
      "|2014-01-01 08:00:00|         3.332204510175204|2.5649493574615367| 2.449489742783178|2.1972245773362196|       1.0|      0|                0|2.3978952727983707|2.3978952727983707|  2.70805020110221|\n",
      "|2014-01-01 09:00:00|        3.4011973816621555| 1.791759469228055|3.7416573867739413|2.1972245773362196|       2.0|      0|                0| 3.332204510175204|2.3978952727983707|2.3978952727983707|\n",
      "|2014-01-01 10:00:00|        4.2626798770413155|  2.70805020110221|               4.0| 3.713572066704308|       0.0|      0|                0|3.4011973816621555| 3.332204510175204|2.3978952727983707|\n",
      "|2014-01-01 11:00:00|          4.68213122712422| 3.044522437723423| 6.244997998398398|3.8712010109078907|       1.0|      0|                0|4.2626798770413155|3.4011973816621555| 3.332204510175204|\n",
      "|2014-01-01 12:00:00|         4.844187086458591|3.6109179126442243|5.5677643628300215|   4.0943445622221|       0.0|      0|                0|  4.68213122712422|4.2626798770413155|3.4011973816621555|\n",
      "|2014-01-01 13:00:00|         4.634728988229636| 3.091042453358316|               4.0| 4.189654742026425|       0.0|      0|                0| 4.844187086458591|  4.68213122712422|4.2626798770413155|\n",
      "|2014-01-01 14:00:00|        4.7535901911063645| 2.833213344056216|  4.47213595499958|4.3694478524670215|       1.0|      0|                0| 4.634728988229636| 4.844187086458591|  4.68213122712422|\n",
      "|2014-01-01 15:00:00|          4.61512051684126| 3.258096538021482| 4.123105625617661|  4.07753744390572|       0.0|      0|                0|4.7535901911063645| 4.634728988229636| 4.844187086458591|\n",
      "|2014-01-01 16:00:00|        3.9318256327243257|2.9444389791664403| 3.872983346207417|2.8903717578961645|       0.0|      0|                0|  4.61512051684126|4.7535901911063645| 4.634728988229636|\n",
      "|2014-01-01 17:00:00|        2.9444389791664403|1.9459101490553132|1.7320508075688772| 2.302585092994046|       0.0|      0|                0|3.9318256327243257|  4.61512051684126|4.7535901911063645|\n",
      "|2014-01-01 18:00:00|        1.3862943611198906|0.6931471805599453|               1.0|               0.0|       1.0|      0|                0|2.9444389791664403|3.9318256327243257|  4.61512051684126|\n",
      "|2014-01-01 19:00:00|         2.833213344056216| 1.791759469228055|1.7320508075688772|1.6094379124341003|       4.0|      0|                0|1.3862943611198906|2.9444389791664403|3.9318256327243257|\n",
      "+-------------------+--------------------------+------------------+------------------+------------------+----------+-------+-----------------+------------------+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import avg, stddev\n",
    "\n",
    "window_spec = Window().orderBy(\"Date\").rowsBetween(-3, 0)  # Last 3 hours\n",
    "\n",
    "df = df.withColumn(\"Rolling_Mean_3H\", avg(\"BGT North of NE 70th Total\").over(window_spec))\n",
    "df = df.withColumn(\"Rolling_Std_3H\", stddev(\"BGT North of NE 70th Total\").over(window_spec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------------+------------------+------------------+------------------+----------+-------+-----------------+------------------+------------------+------------------+------------------+-------------------+\n",
      "|               Date|BGT North of NE 70th Total|         Ped South|         Ped North|        Bike North|Bike South|Anomaly|Anomaly_3hr_Ahead|         Lag_1_day|         Lag_2_day|         Lag_3_day|   Rolling_Mean_3H|     Rolling_Std_3H|\n",
      "+-------------------+--------------------------+------------------+------------------+------------------+----------+-------+-----------------+------------------+------------------+------------------+------------------+-------------------+\n",
      "|2014-01-01 00:00:00|         1.327761429538331|               0.0| 1.189207115002721|0.7412763113750152|      11.0|      0|                0|              NULL|              NULL|              NULL| 1.327761429538331|               NULL|\n",
      "|2014-01-01 01:00:00|        1.1947055233182953|0.5265890341390445|               0.0|0.5265890341390445|       7.0|      0|                0| 1.327761429538331|              NULL|              NULL| 1.261233476428313|0.09408473356510866|\n",
      "|2014-01-01 02:00:00|        1.1947055233182953|               0.0|               0.0|               0.0|       9.0|      0|                0|1.1947055233182953| 1.327761429538331|              NULL| 1.239057492058307|0.07681986327340726|\n",
      "|2014-01-01 03:00:00|        1.3852268599316875|               0.0|               0.0|               0.0|      19.0|      0|                0|1.1947055233182953|1.1947055233182953| 1.327761429538331|1.2755998340266523|0.09630973620748783|\n",
      "|2014-01-01 04:00:00|        1.3852268599316875|               0.0|               0.0|               0.0|      19.0|      0|                0|1.3852268599316875|1.1947055233182953|1.1947055233182953|1.2899661916249914|0.10999754498010927|\n",
      "|2014-01-01 05:00:00|        1.3105061862047918|               0.0|               0.0|               0.0|      14.0|      0|                0|1.3852268599316875|1.3852268599316875|1.1947055233182953|1.3189163573466156|0.08998745796834755|\n",
      "|2014-01-01 06:00:00|         1.223156202527103|               0.0|               1.0|0.5265890341390445|       8.0|      0|                0|1.3105061862047918|1.3852268599316875|1.3852268599316875|1.3260290271488173|0.07709851587201239|\n",
      "|2014-01-01 07:00:00|         1.223156202527103|0.7412763113750152|1.3160740129524924|0.9591348389208239|       1.0|      0|                0| 1.223156202527103|1.3105061862047918|1.3852268599316875|1.2855113627976713|0.07819687459776051|\n",
      "|2014-01-01 08:00:00|        1.4660765372061442|1.2711498482847257|1.5650845800732873|1.1622831138840004|       1.0|      0|                0| 1.223156202527103| 1.223156202527103|1.3105061862047918|1.3057237821162855|  0.114558118950173|\n",
      "|2014-01-01 09:00:00|        1.4818766360989102| 1.026672031199051|1.9343364202676694|1.1622831138840004|       2.0|      0|                0|1.4660765372061442| 1.223156202527103| 1.223156202527103| 1.348566394589815|0.14495480520416923|\n",
      "|2014-01-01 10:00:00|        1.6606403793348097|1.3105061862047918|               2.0|1.5504460211620947|       0.0|      0|                0|1.4818766360989102|1.4660765372061442| 1.223156202527103|1.4579374387917419| 0.1796756717880577|\n",
      "|2014-01-01 11:00:00|        1.7373263784001205|1.3973634811730353|2.4989993994393833| 1.583340520839692|       1.0|      0|                0|1.6606403793348097|1.4818766360989102|1.4660765372061442| 1.586479982759996|0.13378247186096445|\n",
      "|2014-01-01 12:00:00|         1.765447506801529|  1.52842695055997|2.3596110617705666|1.6281310150671582|       0.0|      0|                0|1.7373263784001205|1.6606403793348097|1.4818766360989102|1.6613227251588423|0.12756683206968586|\n",
      "|2014-01-01 13:00:00|        1.7289490519659823|1.4087998161504007|               2.0|1.6466671712706678|       0.0|      0|                0| 1.765447506801529|1.7373263784001205|1.6606403793348097|1.7230908291256104|0.04446390468986966|\n",
      "|2014-01-01 14:00:00|         1.749824041026481|1.3437034446606386| 2.114742526881128|1.6807250824647135|       1.0|      0|                0|1.7289490519659823| 1.765447506801529|1.7373263784001205|1.7453867445485283|0.01588805654246141|\n",
      "|2014-01-01 15:00:00|        1.7254630513334037| 1.448822238365871|2.0305431848689306|1.6248263889219656|       0.0|      0|                0| 1.749824041026481|1.7289490519659823| 1.765447506801529| 1.742420912781849|0.01874469203712867|\n",
      "|2014-01-01 16:00:00|        1.5957092304038698| 1.372306733580753|1.9679896712654306| 1.358504720646626|       0.0|      0|                0|1.7254630513334037| 1.749824041026481|1.7289490519659823| 1.699986343682434|0.07034537069373793|\n",
      "|2014-01-01 17:00:00|         1.372306733580753|1.0804178182729878|1.3160740129524924|1.1947055233182953|       0.0|      0|                0|1.5957092304038698|1.7254630513334037| 1.749824041026481| 1.610825764086127|0.17280245573447192|\n",
      "|2014-01-01 18:00:00|        0.8697416861919438|0.5265890341390445|               1.0|               0.0|       1.0|      0|                0| 1.372306733580753|1.5957092304038698|1.7254630513334037|1.3908051753774924| 0.3767540832854151|\n",
      "|2014-01-01 19:00:00|        1.3437034446606386| 1.026672031199051|1.3160740129524924|0.9591348389208239|       4.0|      0|                0|0.8697416861919438| 1.372306733580753|1.5957092304038698|1.2953652737093013| 0.3052968487620781|\n",
      "+-------------------+--------------------------+------------------+------------------+------------------+----------+-------+-----------------+------------------+------------------+------------------+------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------------+------------------+------------------+------------------+------------------+--------------------+--------------------+------------------+------------------+------------------+------------------+-------------------+\n",
      "|summary|BGT North of NE 70th Total|         Ped South|         Ped North|        Bike North|        Bike South|             Anomaly|   Anomaly_3hr_Ahead|         Lag_1_day|         Lag_2_day|         Lag_3_day|   Rolling_Mean_3H|     Rolling_Std_3H|\n",
      "+-------+--------------------------+------------------+------------------+------------------+------------------+--------------------+--------------------+------------------+------------------+------------------+------------------+-------------------+\n",
      "|  count|                     52584|             52584|             52584|             52584|             52584|               52584|               52581|             52583|             52582|             52581|             52584|              52583|\n",
      "|   mean|        3.0232176979801335|1.5775459219472956| 2.166971088988923|2.0908585445832832|19.838981439221055|0.009432527004411988|0.009433065175633784| 3.023254299265897| 3.023298613044732| 3.023329746044331|3.0232642129246474| 0.6085821361930462|\n",
      "| stddev|        1.8213833388768552|1.3495847370308711| 2.207543267324084| 1.538910086175481|25.163100566219235|  0.0966629822127716|  0.0966657135118246|1.8213813198135709|1.8213702929899673|1.8213736216467522|1.6958512897593927|0.46710237498402407|\n",
      "|    min|                       0.0|               0.0|               0.0|               0.0|               0.0|                   0|                   0|               0.0|               0.0|               0.0|               0.0|                0.0|\n",
      "|    25%|        1.3862943611198906|               0.0|               0.0|0.6931471805599453|               1.0|                   0|                   0|1.3862943611198906|1.3862943611198906|1.3862943611198906|1.4051002164292874|0.23539393510565157|\n",
      "|    50%|         3.367295829986474| 1.791759469228055|               2.0|2.1972245773362196|               9.0|                   0|                   0| 3.367295829986474| 3.367295829986474| 3.367295829986474| 3.311933389437036| 0.5099195431642886|\n",
      "|    75%|          4.51085950651685| 2.639057329615259|3.4641016151377544|3.4011973816621555|              31.0|                   0|                   0|  4.51085950651685|  4.51085950651685|  4.51085950651685| 4.393245700885956| 0.9212268594618147|\n",
      "|    max|         9.258558944246657| 8.307705966549513| 63.99218702310463| 6.678342114654332|              91.0|                   1|                   1| 9.258558944246657| 9.258558944246657| 9.258558944246657| 8.207698466372067|  5.308146400207891|\n",
      "+-------+--------------------------+------------------+------------------+------------------+------------------+--------------------+--------------------+------------------+------------------+------------------+------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df.summary().show()  # Check if there are NULL values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"Bike_Ped_Ratio\", col(\"Bike North\") / (col(\"Ped North\") + 1))\n",
    "df = df.fillna(0)  # Replace all NULLs with 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+\n",
      "|Anomaly_3hr_Ahead|count|\n",
      "+-----------------+-----+\n",
      "|                0|52088|\n",
      "|                1|  496|\n",
      "+-----------------+-----+\n",
      "\n",
      "+-------------------+--------------------------+------------------+------------------+------------------+----------+-------+-----------------+------------------+------------------+------------------+------------------+-------------------+-------------------+\n",
      "|               Date|BGT North of NE 70th Total|         Ped South|         Ped North|        Bike North|Bike South|Anomaly|Anomaly_3hr_Ahead|         Lag_1_day|         Lag_2_day|         Lag_3_day|   Rolling_Mean_3H|     Rolling_Std_3H|     Bike_Ped_Ratio|\n",
      "+-------------------+--------------------------+------------------+------------------+------------------+----------+-------+-----------------+------------------+------------------+------------------+------------------+-------------------+-------------------+\n",
      "|2014-01-01 00:00:00|         2.772588722239781|               0.0|1.4142135623730951|1.0986122886681096|      11.0|      0|                0|               0.0|               0.0|               0.0| 2.772588722239781|                0.0|0.45506010975607675|\n",
      "|2014-01-01 01:00:00|         2.302585092994046|0.6931471805599453|               0.0|0.6931471805599453|       7.0|      0|                0| 2.772588722239781|               0.0|               0.0|2.5375869076169133|0.33234275342194736| 0.6931471805599453|\n",
      "|2014-01-01 02:00:00|         2.302585092994046|               0.0|               0.0|               0.0|       9.0|      0|                0| 2.302585092994046| 2.772588722239781|               0.0| 2.459252969409291|0.27135672186512627|                0.0|\n",
      "|2014-01-01 03:00:00|         2.995732273553991|               0.0|               0.0|               0.0|      19.0|      0|                0| 2.302585092994046| 2.302585092994046| 2.772588722239781| 2.593372795445466|0.34791113512622784|                0.0|\n",
      "|2014-01-01 04:00:00|         2.995732273553991|               0.0|               0.0|               0.0|      19.0|      0|                0| 2.995732273553991| 2.302585092994046| 2.302585092994046| 2.649158683274018| 0.4001887112843144|                0.0|\n",
      "|2014-01-01 05:00:00|          2.70805020110221|               0.0|               0.0|               0.0|      14.0|      0|                0| 2.995732273553991| 2.995732273553991| 2.302585092994046|2.7505249603010595|0.32797737871051796|                0.0|\n",
      "|2014-01-01 06:00:00|        2.3978952727983707|               0.0|               1.0|0.6931471805599453|       8.0|      0|                0|  2.70805020110221| 2.995732273553991| 2.995732273553991|2.7743525052521405| 0.2852683222448084|0.34657359027997264|\n",
      "|2014-01-01 07:00:00|        2.3978952727983707|1.0986122886681096|1.7320508075688772|1.6094379124341003|       1.0|      0|                0|2.3978952727983707|  2.70805020110221| 2.995732273553991|2.6248932550632356|0.28722396790330457| 0.5890951617646756|\n",
      "|2014-01-01 08:00:00|         3.332204510175204|2.5649493574615367| 2.449489742783178|2.1972245773362196|       1.0|      0|                0|2.3978952727983707|2.3978952727983707|  2.70805020110221| 2.709011314218539|0.44043806438704336| 0.6369708974879909|\n",
      "|2014-01-01 09:00:00|        3.4011973816621555| 1.791759469228055|3.7416573867739413|2.1972245773362196|       2.0|      0|                0| 3.332204510175204|2.3978952727983707|2.3978952727983707|2.8822981093585254| 0.5600489384652328| 0.4633874609888537|\n",
      "|2014-01-01 10:00:00|        4.2626798770413155|  2.70805020110221|               4.0| 3.713572066704308|       0.0|      0|                0|3.4011973816621555| 3.332204510175204|2.3978952727983707| 3.348494260419262| 0.7621060188399563| 0.7427144133408616|\n",
      "|2014-01-01 11:00:00|          4.68213122712422| 3.044522437723423| 6.244997998398398|3.8712010109078907|       1.0|      0|                0|4.2626798770413155|3.4011973816621555| 3.332204510175204|3.9195532490007237| 0.6615467738045623| 0.5343274093055196|\n",
      "|2014-01-01 12:00:00|         4.844187086458591|3.6109179126442243|5.5677643628300215|   4.0943445622221|       0.0|      0|                0|  4.68213122712422|4.2626798770413155|3.4011973816621555|  4.29754889307157| 0.6458531222137303| 0.6234000393488333|\n",
      "|2014-01-01 13:00:00|         4.634728988229636| 3.091042453358316|               4.0| 4.189654742026425|       0.0|      0|                0| 4.844187086458591|  4.68213122712422|4.2626798770413155|  4.60593179471344| 0.2457797760084507|  0.837930948405285|\n",
      "|2014-01-01 14:00:00|        4.7535901911063645| 2.833213344056216|  4.47213595499958|4.3694478524670215|       1.0|      0|                0| 4.634728988229636| 4.844187086458591|  4.68213122712422| 4.728659373229703|0.09120669531375704| 0.7984903680024443|\n",
      "|2014-01-01 15:00:00|          4.61512051684126| 3.258096538021482| 4.123105625617661|  4.07753744390572|       0.0|      0|                0|4.7535901911063645| 4.634728988229636| 4.844187086458591| 4.711906695658962|0.10733060842865409| 0.7959112581080381|\n",
      "|2014-01-01 16:00:00|        3.9318256327243257|2.9444389791664403| 3.872983346207417|2.8903717578961645|       0.0|      0|                0|  4.61512051684126|4.7535901911063645| 4.634728988229636|4.4838163322253966| 0.3730447184592848| 0.5931421374845669|\n",
      "|2014-01-01 17:00:00|        2.9444389791664403|1.9459101490553132|1.7320508075688772| 2.302585092994046|       0.0|      0|                0|3.9318256327243257|  4.61512051684126|4.7535901911063645| 4.061243829959597| 0.8266649890967381| 0.8428046384111749|\n",
      "|2014-01-01 18:00:00|        1.3862943611198906|0.6931471805599453|               1.0|               0.0|       1.0|      0|                0|2.9444389791664403|3.9318256327243257|  4.61512051684126| 3.219419872462979| 1.4013643218885559|                0.0|\n",
      "|2014-01-01 19:00:00|         2.833213344056216| 1.791759469228055|1.7320508075688772|1.6094379124341003|       4.0|      0|                0|1.3862943611198906|2.9444389791664403|3.9318256327243257|2.7739430792667186| 1.0486249391062685| 0.5890951617646756|\n",
      "+-------------------+--------------------------+------------------+------------------+------------------+----------+-------+-----------------+------------------+------------------+------------------+------------------+-------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"Anomaly_3hr_Ahead\").count().show()\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when\n",
    "\n",
    "# Compute class weights\n",
    "total_count = df.count()\n",
    "class_counts = df.groupBy(\"Anomaly_3hr_Ahead\").count().collect()\n",
    "\n",
    "# Create a dictionary of class weights\n",
    "class_weights = {row[\"Anomaly_3hr_Ahead\"]: total_count / row[\"count\"] for row in class_counts}\n",
    "\n",
    "# Add weight column\n",
    "df = df.withColumn(\n",
    "    \"class_weight\",\n",
    "    when(col(\"Anomaly_3hr_Ahead\") == 1, class_weights[1]).otherwise(class_weights[0])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns =  [ 'Anomaly_3hr_Ahead', 'Lag_1_day',         'Lag_2_day',         'Lag_3_day',   'Rolling_Mean_3H',     'Rolling_Std_3H']\n",
    "for col_name in columns:\n",
    "    df = df.withColumn(col_name,col(col_name).cast('double'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Date', 'BGT North of NE 70th Total', 'Ped South', 'Ped North', 'Bike North', 'Bike South', 'Anomaly', 'Anomaly_3hr_Ahead', 'Lag_1_day', 'Lag_2_day', 'Lag_3_day', 'Rolling_Mean_3H', 'Rolling_Std_3H', 'Bike_Ped_Ratio', 'class_weight']\n"
     ]
    }
   ],
   "source": [
    "col = df.columns\n",
    "print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------------+------------------+------------------+------------------+----------+-------+-----------------+------------------+------------------+------------------+------------------+-------------------+-------------------+-----------------+\n",
      "|               Date|BGT North of NE 70th Total|         Ped South|         Ped North|        Bike North|Bike South|Anomaly|Anomaly_3hr_Ahead|         Lag_1_day|         Lag_2_day|         Lag_3_day|   Rolling_Mean_3H|     Rolling_Std_3H|     Bike_Ped_Ratio|     class_weight|\n",
      "+-------------------+--------------------------+------------------+------------------+------------------+----------+-------+-----------------+------------------+------------------+------------------+------------------+-------------------+-------------------+-----------------+\n",
      "|2014-01-01 00:00:00|         1.327761429538331|               0.0| 1.189207115002721|0.7412763113750152|      11.0|      0|              0.0|               0.0|               0.0|               0.0| 1.327761429538331|                0.0|0.33860492517817065|1.009522346797727|\n",
      "|2014-01-01 01:00:00|        1.1947055233182953|0.5265890341390445|               0.0|0.5265890341390445|       7.0|      0|              0.0| 1.327761429538331|               0.0|               0.0| 1.261233476428313|0.09408473356510866| 0.5265890341390445|1.009522346797727|\n",
      "|2014-01-01 02:00:00|        1.1947055233182953|               0.0|               0.0|               0.0|       9.0|      0|              0.0|1.1947055233182953| 1.327761429538331|               0.0| 1.239057492058307|0.07681986327340726|                0.0|1.009522346797727|\n",
      "|2014-01-01 03:00:00|        1.3852268599316875|               0.0|               0.0|               0.0|      19.0|      0|              0.0|1.1947055233182953|1.1947055233182953| 1.327761429538331|1.2755998340266523|0.09630973620748783|                0.0|1.009522346797727|\n",
      "|2014-01-01 04:00:00|        1.3852268599316875|               0.0|               0.0|               0.0|      19.0|      0|              0.0|1.3852268599316875|1.1947055233182953|1.1947055233182953|1.2899661916249914|0.10999754498010927|                0.0|1.009522346797727|\n",
      "|2014-01-01 05:00:00|        1.3105061862047918|               0.0|               0.0|               0.0|      14.0|      0|              0.0|1.3852268599316875|1.3852268599316875|1.1947055233182953|1.3189163573466156|0.08998745796834755|                0.0|1.009522346797727|\n",
      "|2014-01-01 06:00:00|         1.223156202527103|               0.0|               1.0|0.5265890341390445|       8.0|      0|              0.0|1.3105061862047918|1.3852268599316875|1.3852268599316875|1.3260290271488173|0.07709851587201239| 0.2632945170695222|1.009522346797727|\n",
      "|2014-01-01 07:00:00|         1.223156202527103|0.7412763113750152|1.3160740129524924|0.9591348389208239|       1.0|      0|              0.0| 1.223156202527103|1.3105061862047918|1.3852268599316875|1.2855113627976713|0.07819687459776051|0.41412097953559557|1.009522346797727|\n",
      "|2014-01-01 08:00:00|        1.4660765372061442|1.2711498482847257|1.5650845800732873|1.1622831138840004|       1.0|      0|              0.0| 1.223156202527103| 1.223156202527103|1.3105061862047918|1.3057237821162855|  0.114558118950173| 0.4531168768909728|1.009522346797727|\n",
      "|2014-01-01 09:00:00|        1.4818766360989102| 1.026672031199051|1.9343364202676694|1.1622831138840004|       2.0|      0|              0.0|1.4660765372061442| 1.223156202527103| 1.223156202527103| 1.348566394589815|0.14495480520416923| 0.3960974296798515|1.009522346797727|\n",
      "|2014-01-01 10:00:00|        1.6606403793348097|1.3105061862047918|               2.0|1.5504460211620947|       0.0|      0|              0.0|1.4818766360989102|1.4660765372061442| 1.223156202527103|1.4579374387917419| 0.1796756717880577| 0.5168153403873649|1.009522346797727|\n",
      "|2014-01-01 11:00:00|        1.7373263784001205|1.3973634811730353|2.4989993994393833| 1.583340520839692|       1.0|      0|              0.0|1.6606403793348097|1.4818766360989102|1.4660765372061442| 1.586479982759996|0.13378247186096445|0.45251237284961465|1.009522346797727|\n",
      "|2014-01-01 12:00:00|         1.765447506801529|  1.52842695055997|2.3596110617705666|1.6281310150671582|       0.0|      0|              0.0|1.7373263784001205|1.6606403793348097|1.4818766360989102|1.6613227251588423|0.12756683206968586|0.48461889937018726|1.009522346797727|\n",
      "|2014-01-01 13:00:00|        1.7289490519659823|1.4087998161504007|               2.0|1.6466671712706678|       0.0|      0|              0.0| 1.765447506801529|1.7373263784001205|1.6606403793348097|1.7230908291256104|0.04446390468986966| 0.5488890570902226|1.009522346797727|\n",
      "|2014-01-01 14:00:00|         1.749824041026481|1.3437034446606386| 2.114742526881128|1.6807250824647135|       1.0|      0|              0.0|1.7289490519659823| 1.765447506801529|1.7373263784001205|1.7453867445485283|0.01588805654246141| 0.5396032153410981|1.009522346797727|\n",
      "|2014-01-01 15:00:00|        1.7254630513334037| 1.448822238365871|2.0305431848689306|1.6248263889219656|       0.0|      0|              0.0| 1.749824041026481|1.7289490519659823| 1.765447506801529| 1.742420912781849|0.01874469203712867| 0.5361502178997124|1.009522346797727|\n",
      "|2014-01-01 16:00:00|        1.5957092304038698| 1.372306733580753|1.9679896712654306| 1.358504720646626|       0.0|      0|              0.0|1.7254630513334037| 1.749824041026481|1.7289490519659823| 1.699986343682434|0.07034537069373793| 0.4577188168136093|1.009522346797727|\n",
      "|2014-01-01 17:00:00|         1.372306733580753|1.0804178182729878|1.3160740129524924|1.1947055233182953|       0.0|      0|              0.0|1.5957092304038698|1.7254630513334037| 1.749824041026481| 1.610825764086127|0.17280245573447192| 0.5158321869840872|1.009522346797727|\n",
      "|2014-01-01 18:00:00|        0.8697416861919438|0.5265890341390445|               1.0|               0.0|       1.0|      0|              0.0| 1.372306733580753|1.5957092304038698|1.7254630513334037|1.3908051753774924| 0.3767540832854151|                0.0|1.009522346797727|\n",
      "|2014-01-01 19:00:00|        1.3437034446606386| 1.026672031199051|1.3160740129524924|0.9591348389208239|       4.0|      0|              0.0|0.8697416861919438| 1.372306733580753|1.5957092304038698|1.2953652737093013| 0.3052968487620781|0.41412097953559557|1.009522346797727|\n",
      "+-------------------+--------------------------+------------------+------------------+------------------+----------+-------+-----------------+------------------+------------------+------------------+------------------+-------------------+-------------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------------+---------+---------+----------+----------+-------+-----------------+---------+---------+---------+---------------+--------------+--------------+------------+\n",
      "|Date|BGT North of NE 70th Total|Ped South|Ped North|Bike North|Bike South|Anomaly|Anomaly_3hr_Ahead|Lag_1_day|Lag_2_day|Lag_3_day|Rolling_Mean_3H|Rolling_Std_3H|Bike_Ped_Ratio|class_weight|\n",
      "+----+--------------------------+---------+---------+----------+----------+-------+-----------------+---------+---------+---------+---------------+--------------+--------------+------------+\n",
      "|   0|                         0|        0|        0|         0|         0|      0|                0|        0|        0|        0|              0|             0|             0|           0|\n",
      "+----+--------------------------+---------+---------+----------+----------+-------+-----------------+---------+---------+---------+---------------+--------------+--------------+------------+\n",
      "\n",
      "+-------+--------------------------+------------------+-----------------+------------------+------------------+--------------------+--------------------+------------------+------------------+------------------+------------------+-------------------+------------------+------------------+\n",
      "|summary|BGT North of NE 70th Total|         Ped South|        Ped North|        Bike North|        Bike South|             Anomaly|   Anomaly_3hr_Ahead|         Lag_1_day|         Lag_2_day|         Lag_3_day|   Rolling_Mean_3H|     Rolling_Std_3H|    Bike_Ped_Ratio|      class_weight|\n",
      "+-------+--------------------------+------------------+-----------------+------------------+------------------+--------------------+--------------------+------------------+------------------+------------------+------------------+-------------------+------------------+------------------+\n",
      "|  count|                     52584|             52584|            52584|             52584|             52584|               52584|               52584|             52584|             52584|             52584|             52584|              52584|             52584|             52584|\n",
      "|   mean|        3.0232176979801335|1.5775459219472956|2.166971088988923|2.0908585445832832|19.838981439221055|0.009432527004411988|0.009432527004411988|3.0231968054598104|3.0231836237471112|3.0231572603217134|3.0232642129246474| 0.6085705626699938|0.6189295223067984|1.9999999999984837|\n",
      "| stddev|        1.8213833388768552|1.3495847370308711|2.207543267324084| 1.538910086175481|25.163100566219235|  0.0966629822127716| 0.09666298221277163| 1.821411716543622|1.8214310877129196|1.8214648128394677|1.6958512897593927|0.46710547290447463|0.4522142700559596|10.150251754260182|\n",
      "|    min|                       0.0|               0.0|              0.0|               0.0|               0.0|                   0|                 0.0|               0.0|               0.0|               0.0|               0.0|                0.0|               0.0| 1.009522346797727|\n",
      "|    max|         9.258558944246657| 8.307705966549513|63.99218702310463| 6.678342114654332|              91.0|                   1|                 1.0| 9.258558944246657| 9.258558944246657| 9.258558944246657| 8.207698466372067|  5.308146400207891|5.0369526024136295|106.01612903225806|\n",
      "+-------+--------------------------+------------------+-----------------+------------------+------------------+--------------------+--------------------+------------------+------------------+------------------+------------------+-------------------+------------------+------------------+\n",
      "\n",
      "+-------+--------------------------+------------------+------------------+------------------+------------------+--------------------+--------------------+------------------+------------------+------------------+------------------+-------------------+-------------------+------------------+\n",
      "|summary|BGT North of NE 70th Total|         Ped South|         Ped North|        Bike North|        Bike South|             Anomaly|   Anomaly_3hr_Ahead|         Lag_1_day|         Lag_2_day|         Lag_3_day|   Rolling_Mean_3H|     Rolling_Std_3H|     Bike_Ped_Ratio|      class_weight|\n",
      "+-------+--------------------------+------------------+------------------+------------------+------------------+--------------------+--------------------+------------------+------------------+------------------+------------------+-------------------+-------------------+------------------+\n",
      "|  count|                     52584|             52584|             52584|             52584|             52584|               52584|               52584|             52584|             52584|             52584|             52584|              52584|              52584|             52584|\n",
      "|   mean|        3.0232176979801335|1.5775459219472956| 2.166971088988923|2.0908585445832832|19.838981439221055|0.009432527004411988|0.009432527004411988|3.0231968054598104|3.0231836237471112|3.0231572603217134|3.0232642129246474| 0.6085705626699938| 0.6189295223067984|1.9999999999984837|\n",
      "| stddev|        1.8213833388768552|1.3495847370308711| 2.207543267324084| 1.538910086175481|25.163100566219235|  0.0966629822127716| 0.09666298221277163| 1.821411716543622|1.8214310877129196|1.8214648128394677|1.6958512897593927|0.46710547290447463| 0.4522142700559596|10.150251754260182|\n",
      "|    min|                       0.0|               0.0|               0.0|               0.0|               0.0|                   0|                 0.0|               0.0|               0.0|               0.0|               0.0|                0.0|                0.0| 1.009522346797727|\n",
      "|    25%|        1.3862943611198906|               0.0|               0.0|0.6931471805599453|               1.0|                   0|                 0.0|1.3862943611198906|1.3862943611198906|1.3862943611198906|1.4051002164292874|0.23531960941550423|0.34657359027997264| 1.009522346797727|\n",
      "|    50%|         3.367295829986474| 1.791759469228055|               2.0|2.1972245773362196|               9.0|                   0|                 0.0| 3.367295829986474| 3.367295829986474| 3.367295829986474| 3.311933389437036| 0.5098933509941068| 0.6931471805599453| 1.009522346797727|\n",
      "|    75%|          4.51085950651685| 2.639057329615259|3.4641016151377544|3.4011973816621555|              31.0|                   0|                 0.0|  4.51085950651685|  4.51085950651685|  4.51085950651685| 4.393245700885956| 0.9212268594618147| 0.8221747728346622| 1.009522346797727|\n",
      "|    max|         9.258558944246657| 8.307705966549513| 63.99218702310463| 6.678342114654332|              91.0|                   1|                 1.0| 9.258558944246657| 9.258558944246657| 9.258558944246657| 8.207698466372067|  5.308146400207891| 5.0369526024136295|106.01612903225806|\n",
      "+-------+--------------------------+------------------+------------------+------------------+------------------+--------------------+--------------------+------------------+------------------+------------------+------------------+-------------------+-------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, sum, when\n",
    "\n",
    "# Count nulls for each column\n",
    "null_counts = df.select(\n",
    "        [sum(when(col(c).isNull(), 1).otherwise(0)).alias(c) for c in df.columns]\n",
    "    )\n",
    "    \n",
    "    # Show the result\n",
    "null_counts.show()\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Check if there are nulls in the entire DataFrame\n",
    "df.describe().show()  # This gives summary statistics\n",
    "df.summary().show()  # More detailed stats\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import hour, dayofweek, month\n",
    "\n",
    "df = df.withColumn(\"Hour\", hour(\"Date\"))\n",
    "df = df.withColumn(\"DayOfWeek\", dayofweek(\"Date\"))\n",
    "df = df.withColumn(\"Month\", month(\"Date\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, hour,dayofweek, month, weekofyear, avg, when, stddev, mean\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "#compute weeks of year\n",
    "df = df.withColumn('Week of year', weekofyear('Date'))\n",
    "\n",
    "#compute hourly traffic trend\n",
    "hourly_traffic = df.groupBy('Hour').agg(avg('BGT North of NE 70th Total').alias('average hourly traffic'))\n",
    "\n",
    "#compute day of week traffic trend\n",
    "weekly_traffic = df.groupBy(\"DayOfWeek\").agg(avg(\"BGT North of NE 70th Total\").alias(\"Avg_Traffic\"))\n",
    "\n",
    "# compute monthly traffic average\n",
    "monthly_traffic = df.groupBy('Month').agg(avg('BGT North of NE 70th Total').alias('average momthly traffic trend'))\n",
    "\n",
    "#compute weeks of year traffic trend\n",
    "week_year_traffic = df.groupBy('Week of year').agg(avg('BGT North of NE 70th Total').alias('average weeks of year traffic trend'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[DayOfWeek: int, Avg_Traffic: double] DataFrame[Month: int, average momthly traffic trend: double] DataFrame[Hour: int, average hourly traffic: double]\n",
      "+----+----------------------+\n",
      "|Hour|average hourly traffic|\n",
      "+----+----------------------+\n",
      "|  12|     4.312052262093978|\n",
      "|  22|    1.5723374070860288|\n",
      "|   1|    0.5445643544259441|\n",
      "|  13|     4.314566616722907|\n",
      "|   6|     3.312977090064919|\n",
      "|  16|     4.605380924068011|\n",
      "|   3|    0.5803882281959689|\n",
      "|  20|     2.796391459593819|\n",
      "|   5|     2.301046095158892|\n",
      "|  19|    3.4685188351360003|\n",
      "|  15|     4.449245531903663|\n",
      "|   9|    4.3541667047153325|\n",
      "|  17|     4.544971291138357|\n",
      "|   4|    1.3098592718114497|\n",
      "|   8|     4.384738261906119|\n",
      "|  23|    1.1130467358469607|\n",
      "|   7|     4.028916289621279|\n",
      "|  10|     4.303854154631774|\n",
      "|  21|     2.159241153522885|\n",
      "|  11|      4.29659043272963|\n",
      "+----+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(weekly_traffic,monthly_traffic,hourly_traffic)\n",
    "# weekly_traffic.show()\n",
    "# monthly_traffic.show()\n",
    "hourly_traffic.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Rolling Averages\n",
    "window_spec = Window.orderBy(\"Date\").rowsBetween(-6, 0)\n",
    "df = df.withColumn(\"Rolling_7Day_Avg\", avg(\"BGT North of NE 70th Total\").over(window_spec))\n",
    "\n",
    "#  Detect Anomalies Using Z-Score\n",
    "traffic_stats = df.select(\n",
    "    mean(col(\"BGT North of NE 70th Total\")).alias(\"Mean_Traffic\"),\n",
    "    stddev(col(\"BGT North of NE 70th Total\")).alias(\"StdDev_Traffic\")\n",
    ").collect()\n",
    "\n",
    "mean_traffic = traffic_stats[0][\"Mean_Traffic\"]\n",
    "stddev_traffic = traffic_stats[0][\"StdDev_Traffic\"]\n",
    "\n",
    "df = df.withColumn(\"Z-Score\", (col(\"BGT North of NE 70th Total\") - mean_traffic) / stddev_traffic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('final_target_column',col('final_target_column').cast('double'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------------+------------------+------------------+------------------+----------+-------+-----------------+------------------+------------------+------------------+------------------+-------------------+-------------------+-----------------+----+---------+-----+------------+------------------+--------------------+---------------+-------------------+\n",
      "|               Date|BGT North of NE 70th Total|         Ped South|         Ped North|        Bike North|Bike South|Anomaly|Anomaly_3hr_Ahead|         Lag_1_day|         Lag_2_day|         Lag_3_day|   Rolling_Mean_3H|     Rolling_Std_3H|     Bike_Ped_Ratio|     class_weight|Hour|DayOfWeek|Month|Week of year|  Rolling_7Day_Avg|             Z-Score|z-score_anomaly|final_target_column|\n",
      "+-------------------+--------------------------+------------------+------------------+------------------+----------+-------+-----------------+------------------+------------------+------------------+------------------+-------------------+-------------------+-----------------+----+---------+-----+------------+------------------+--------------------+---------------+-------------------+\n",
      "|2014-01-01 00:00:00|         2.772588722239781|               0.0|1.4142135623730951|1.0986122886681096|      11.0|      0|              0.0|               0.0|               0.0|               0.0| 2.772588722239781|                0.0|0.45506010975607675|1.009522346797727|   0|        4|    1|           1| 2.772588722239781|-0.13760363916302273|              0|                  0|\n",
      "|2014-01-01 01:00:00|         2.302585092994046|0.6931471805599453|               0.0|0.6931471805599453|       7.0|      0|              0.0| 2.772588722239781|               0.0|               0.0|2.5375869076169133|0.33234275342194736| 0.6931471805599453|1.009522346797727|   1|        4|    1|           1|2.5375869076169133|-0.39565125561676723|              0|                  0|\n",
      "|2014-01-01 02:00:00|         2.302585092994046|               0.0|               0.0|               0.0|       9.0|      0|              0.0| 2.302585092994046| 2.772588722239781|               0.0| 2.459252969409291|0.27135672186512627|                0.0|1.009522346797727|   2|        4|    1|           1| 2.459252969409291|-0.39565125561676723|              0|                  0|\n",
      "|2014-01-01 03:00:00|         2.995732273553991|               0.0|               0.0|               0.0|      19.0|      0|              0.0| 2.302585092994046| 2.302585092994046| 2.772588722239781| 2.593372795445466|0.34791113512622784|                0.0|1.009522346797727|   3|        4|    1|           1| 2.593372795445466|-0.01509041168845...|              0|                  0|\n",
      "|2014-01-01 04:00:00|         2.995732273553991|               0.0|               0.0|               0.0|      19.0|      0|              0.0| 2.995732273553991| 2.302585092994046| 2.302585092994046| 2.649158683274018| 0.4001887112843144|                0.0|1.009522346797727|   4|        4|    1|           1| 2.673844691067171|-0.01509041168845...|              0|                  0|\n",
      "|2014-01-01 05:00:00|          2.70805020110221|               0.0|               0.0|               0.0|      14.0|      0|              0.0| 2.995732273553991| 2.995732273553991| 2.302585092994046|2.7505249603010595|0.32797737871051796|                0.0|1.009522346797727|   5|        4|    1|           1|2.6795456094063437| -0.1730374326759075|              0|                  0|\n",
      "|2014-01-01 06:00:00|        2.3978952727983707|               0.0|               1.0|0.6931471805599453|       8.0|      0|              0.0|  2.70805020110221| 2.995732273553991| 2.995732273553991|2.7743525052521405| 0.2852683222448084|0.34657359027997264|1.009522346797727|   6|        4|    1|           1| 2.639309847033776| -0.3433227985753752|              0|                  0|\n",
      "|2014-01-01 07:00:00|        2.3978952727983707|1.0986122886681096|1.7320508075688772|1.6094379124341003|       1.0|      0|              0.0|2.3978952727983707|  2.70805020110221| 2.995732273553991|2.6248932550632356|0.28722396790330457| 0.5890951617646756|1.009522346797727|   7|        4|    1|           1|2.5857822113992888| -0.3433227985753752|              0|                  0|\n",
      "|2014-01-01 08:00:00|         3.332204510175204|2.5649493574615367| 2.449489742783178|2.1972245773362196|       1.0|      0|              0.0|2.3978952727983707|2.3978952727983707|  2.70805020110221| 2.709011314218539|0.44043806438704336| 0.6369708974879909|1.009522346797727|   8|        4|    1|           1| 2.732870699568026| 0.16964403132489678|              0|                  0|\n",
      "|2014-01-01 09:00:00|        3.4011973816621555| 1.791759469228055|3.7416573867739413|2.1972245773362196|       2.0|      0|              0.0| 3.332204510175204|2.3978952727983707|2.3978952727983707|2.8822981093585254| 0.5600489384652328| 0.4633874609888537|1.009522346797727|   9|        4|    1|           1|2.8898153122348984| 0.20752341125240598|              0|                  0|\n",
      "+-------------------+--------------------------+------------------+------------------+------------------+----------+-------+-----------------+------------------+------------------+------------------+------------------+-------------------+-------------------+-----------------+----+---------+-----+------------+------------------+--------------------+---------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import abs, col, when\n",
    "\n",
    "df = df.withColumn(\"z-score_anomaly\", when(abs(col(\"Z-Score\")) > 2, 1).otherwise(0))\n",
    "df = df.withColumn('final_target_column',  lag(\"z-score_anomaly\", -3).over(Window.orderBy(\"Date\")))\n",
    "# Show results\n",
    "df.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|summary| final_target_column|\n",
      "+-------+--------------------+\n",
      "|  count|               52581|\n",
      "|   mean|0.007550255795819783|\n",
      "| stddev|  0.0865643803457163|\n",
      "|    min|                 0.0|\n",
      "|    25%|                 0.0|\n",
      "|    50%|                 0.0|\n",
      "|    75%|                 0.0|\n",
      "|    max|                 1.0|\n",
      "+-------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"final_target_column\").summary().show()\n",
    "df = df.na.drop(subset=[\"final_target_column\"])\n",
    "df = df.na.fill({\"final_target_column\": 0})  # Assuming 0 means \"not anomaly\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------------+------------------+------------------+------------------+----------+-------+-----------------+------------------+------------------+------------------+------------------+-------------------+-------------------+-----------------+----+---------+-----+------------+------------------+--------------------+---------------+-------------------+\n",
      "|               Date|BGT North of NE 70th Total|         Ped South|         Ped North|        Bike North|Bike South|Anomaly|Anomaly_3hr_Ahead|         Lag_1_day|         Lag_2_day|         Lag_3_day|   Rolling_Mean_3H|     Rolling_Std_3H|     Bike_Ped_Ratio|     class_weight|Hour|DayOfWeek|Month|Week of year|  Rolling_7Day_Avg|             Z-Score|z-score_anomaly|final_target_column|\n",
      "+-------------------+--------------------------+------------------+------------------+------------------+----------+-------+-----------------+------------------+------------------+------------------+------------------+-------------------+-------------------+-----------------+----+---------+-----+------------+------------------+--------------------+---------------+-------------------+\n",
      "|2014-01-01 00:00:00|         2.772588722239781|               0.0|1.4142135623730951|1.0986122886681096|      11.0|      0|              0.0|               0.0|               0.0|               0.0| 2.772588722239781|                0.0|0.45506010975607675|1.009522346797727|   0|        4|    1|           1| 2.772588722239781|-0.13760363916302273|              0|                0.0|\n",
      "|2014-01-01 01:00:00|         2.302585092994046|0.6931471805599453|               0.0|0.6931471805599453|       7.0|      0|              0.0| 2.772588722239781|               0.0|               0.0|2.5375869076169133|0.33234275342194736| 0.6931471805599453|1.009522346797727|   1|        4|    1|           1|2.5375869076169133|-0.39565125561676723|              0|                0.0|\n",
      "|2014-01-01 02:00:00|         2.302585092994046|               0.0|               0.0|               0.0|       9.0|      0|              0.0| 2.302585092994046| 2.772588722239781|               0.0| 2.459252969409291|0.27135672186512627|                0.0|1.009522346797727|   2|        4|    1|           1| 2.459252969409291|-0.39565125561676723|              0|                0.0|\n",
      "|2014-01-01 03:00:00|         2.995732273553991|               0.0|               0.0|               0.0|      19.0|      0|              0.0| 2.302585092994046| 2.302585092994046| 2.772588722239781| 2.593372795445466|0.34791113512622784|                0.0|1.009522346797727|   3|        4|    1|           1| 2.593372795445466|-0.01509041168845...|              0|                0.0|\n",
      "|2014-01-01 04:00:00|         2.995732273553991|               0.0|               0.0|               0.0|      19.0|      0|              0.0| 2.995732273553991| 2.302585092994046| 2.302585092994046| 2.649158683274018| 0.4001887112843144|                0.0|1.009522346797727|   4|        4|    1|           1| 2.673844691067171|-0.01509041168845...|              0|                0.0|\n",
      "|2014-01-01 05:00:00|          2.70805020110221|               0.0|               0.0|               0.0|      14.0|      0|              0.0| 2.995732273553991| 2.995732273553991| 2.302585092994046|2.7505249603010595|0.32797737871051796|                0.0|1.009522346797727|   5|        4|    1|           1|2.6795456094063437| -0.1730374326759075|              0|                0.0|\n",
      "|2014-01-01 06:00:00|        2.3978952727983707|               0.0|               1.0|0.6931471805599453|       8.0|      0|              0.0|  2.70805020110221| 2.995732273553991| 2.995732273553991|2.7743525052521405| 0.2852683222448084|0.34657359027997264|1.009522346797727|   6|        4|    1|           1| 2.639309847033776| -0.3433227985753752|              0|                0.0|\n",
      "|2014-01-01 07:00:00|        2.3978952727983707|1.0986122886681096|1.7320508075688772|1.6094379124341003|       1.0|      0|              0.0|2.3978952727983707|  2.70805020110221| 2.995732273553991|2.6248932550632356|0.28722396790330457| 0.5890951617646756|1.009522346797727|   7|        4|    1|           1|2.5857822113992888| -0.3433227985753752|              0|                0.0|\n",
      "|2014-01-01 08:00:00|         3.332204510175204|2.5649493574615367| 2.449489742783178|2.1972245773362196|       1.0|      0|              0.0|2.3978952727983707|2.3978952727983707|  2.70805020110221| 2.709011314218539|0.44043806438704336| 0.6369708974879909|1.009522346797727|   8|        4|    1|           1| 2.732870699568026| 0.16964403132489678|              0|                0.0|\n",
      "|2014-01-01 09:00:00|        3.4011973816621555| 1.791759469228055|3.7416573867739413|2.1972245773362196|       2.0|      0|              0.0| 3.332204510175204|2.3978952727983707|2.3978952727983707|2.8822981093585254| 0.5600489384652328| 0.4633874609888537|1.009522346797727|   9|        4|    1|           1|2.8898153122348984| 0.20752341125240598|              0|                0.0|\n",
      "|2014-01-01 10:00:00|        4.2626798770413155|  2.70805020110221|               4.0| 3.713572066704308|       0.0|      0|              0.0|3.4011973816621555| 3.332204510175204|2.3978952727983707| 3.348494260419262| 0.7621060188399563| 0.7427144133408616|1.009522346797727|  10|        4|    1|           1|3.0708078270188026|    0.68050593886814|              0|                0.0|\n",
      "|2014-01-01 11:00:00|          4.68213122712422| 3.044522437723423| 6.244997998398398|3.8712010109078907|       1.0|      0|              0.0|4.2626798770413155|3.4011973816621555| 3.332204510175204|3.9195532490007237| 0.6615467738045623| 0.5343274093055196|1.009522346797727|  11|        4|    1|           1|3.3117219632431207|  0.9107986735878704|              0|                0.0|\n",
      "|2014-01-01 12:00:00|         4.844187086458591|3.6109179126442243|5.5677643628300215|   4.0943445622221|       0.0|      0|              0.0|  4.68213122712422|4.2626798770413155|3.4011973816621555|  4.29754889307157| 0.6458531222137303| 0.6234000393488333|1.009522346797727|  12|        4|    1|           1|3.6168843754368893|  0.9997727274706197|              0|                0.0|\n",
      "|2014-01-01 13:00:00|         4.634728988229636| 3.091042453358316|               4.0| 4.189654742026425|       0.0|      0|              0.0| 4.844187086458591|  4.68213122712422|4.2626798770413155|  4.60593179471344| 0.2457797760084507|  0.837930948405285|1.009522346797727|  13|        4|    1|           1| 3.936432049069928|  0.8847732686756818|              0|                0.0|\n",
      "|2014-01-01 14:00:00|        4.7535901911063645| 2.833213344056216|  4.47213595499958|4.3694478524670215|       1.0|      0|              0.0| 4.634728988229636| 4.844187086458591|  4.68213122712422| 4.728659373229703|0.09120669531375704| 0.7984903680024443|1.009522346797727|  14|        4|    1|           1| 4.272959894542498|  0.9500320202738071|              0|                0.0|\n",
      "|2014-01-01 15:00:00|          4.61512051684126| 3.258096538021482| 4.123105625617661|  4.07753744390572|       0.0|      0|              0.0|4.7535901911063645| 4.634728988229636| 4.844187086458591| 4.711906695658962|0.10733060842865409| 0.7959112581080381|1.009522346797727|  15|        4|    1|           1| 4.456233609780506|  0.8740075660529338|              0|                0.0|\n",
      "|2014-01-01 16:00:00|        3.9318256327243257|2.9444389791664403| 3.872983346207417|2.8903717578961645|       0.0|      0|              0.0|  4.61512051684126|4.7535901911063645| 4.634728988229636|4.4838163322253966| 0.3730447184592848| 0.5931421374845669|1.009522346797727|  16|        4|    1|           1|  4.53203764564653| 0.49885596038474783|              0|                0.0|\n",
      "|2014-01-01 17:00:00|        2.9444389791664403|1.9459101490553132|1.7320508075688772| 2.302585092994046|       0.0|      0|              0.0|3.9318256327243257|  4.61512051684126|4.7535901911063645| 4.061243829959597| 0.8266649890967381| 0.8428046384111749|1.009522346797727|  17|        4|    1|           1| 4.343717517378691|-0.04325213541388363|              0|                0.0|\n",
      "|2014-01-01 18:00:00|        1.3862943611198906|0.6931471805599453|               1.0|               0.0|       1.0|      0|              0.0|2.9444389791664403|3.9318256327243257|  4.61512051684126| 3.219419872462979| 1.4013643218885559|                0.0|1.009522346797727|  18|        4|    1|           1|3.8728836793780728| -0.8987253270196496|              0|                0.0|\n",
      "|2014-01-01 19:00:00|         2.833213344056216| 1.791759469228055|1.7320508075688772|1.6094379124341003|       4.0|      0|              0.0|1.3862943611198906|2.9444389791664403|3.9318256327243257|2.7739430792667186| 1.0486249391062685| 0.5890951617646756|1.009522346797727|  19|        4|    1|           1|3.5856017161777336|-0.10431870648442539|              0|                0.0|\n",
      "+-------------------+--------------------------+------------------+------------------+------------------+----------+-------+-----------------+------------------+------------------+------------------+------------------+-------------------+-------------------+-----------------+----+---------+-----+------------+------------------+--------------------+---------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.dropna()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute '_get_object_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[132], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Convert to Pandas DataFrame\u001b[39;00m\n\u001b[0;32m      5\u001b[0m pandas_df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mtoPandas()\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\anaconda3\\envs\\anomaly_detect\\lib\\site-packages\\pyspark\\sql\\readwriter.py:484\u001b[0m, in \u001b[0;36mDataFrameReader.table\u001b[1;34m(self, tableName)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtable\u001b[39m(\u001b[38;5;28mself\u001b[39m, tableName: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    451\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns the specified table as a :class:`DataFrame`.\u001b[39;00m\n\u001b[0;32m    452\u001b[0m \n\u001b[0;32m    453\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 1.4.0\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;124;03m    >>> _ = spark.sql(\"DROP TABLE tblA\")\u001b[39;00m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 484\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtableName\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\anaconda3\\envs\\anomaly_detect\\lib\\site-packages\\py4j\\java_gateway.py:1314\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1313\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m-> 1314\u001b[0m     args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_args\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1316\u001b[0m     command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m         args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m         proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m     answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\anaconda3\\envs\\anomaly_detect\\lib\\site-packages\\py4j\\java_gateway.py:1283\u001b[0m, in \u001b[0;36mJavaMember._build_args\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1279\u001b[0m     new_args \u001b[38;5;241m=\u001b[39m args\n\u001b[0;32m   1280\u001b[0m     temp_args \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   1282\u001b[0m args_command \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m-> 1283\u001b[0m     [get_command_part(arg, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m new_args])\n\u001b[0;32m   1285\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m args_command, temp_args\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\anaconda3\\envs\\anomaly_detect\\lib\\site-packages\\py4j\\java_gateway.py:1283\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1279\u001b[0m     new_args \u001b[38;5;241m=\u001b[39m args\n\u001b[0;32m   1280\u001b[0m     temp_args \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   1282\u001b[0m args_command \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m-> 1283\u001b[0m     [\u001b[43mget_command_part\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpool\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m new_args])\n\u001b[0;32m   1285\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m args_command, temp_args\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\anaconda3\\envs\\anomaly_detect\\lib\\site-packages\\py4j\\protocol.py:298\u001b[0m, in \u001b[0;36mget_command_part\u001b[1;34m(parameter, python_proxy_pool)\u001b[0m\n\u001b[0;32m    296\u001b[0m         command_part \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m interface\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 298\u001b[0m     command_part \u001b[38;5;241m=\u001b[39m REFERENCE_TYPE \u001b[38;5;241m+\u001b[39m \u001b[43mparameter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_object_id\u001b[49m()\n\u001b[0;32m    300\u001b[0m command_part \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m command_part\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\anaconda3\\envs\\anomaly_detect\\lib\\site-packages\\pyspark\\sql\\dataframe.py:3129\u001b[0m, in \u001b[0;36mDataFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   3096\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the :class:`Column` denoted by ``name``.\u001b[39;00m\n\u001b[0;32m   3097\u001b[0m \n\u001b[0;32m   3098\u001b[0m \u001b[38;5;124;03m.. versionadded:: 1.3.0\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3126\u001b[0m \u001b[38;5;124;03m+---+\u001b[39;00m\n\u001b[0;32m   3127\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[1;32m-> 3129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m   3130\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name)\n\u001b[0;32m   3131\u001b[0m     )\n\u001b[0;32m   3132\u001b[0m jc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jdf\u001b[38;5;241m.\u001b[39mapply(name)\n\u001b[0;32m   3133\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Column(jc)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute '_get_object_id'"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "import pandas as pd\n",
    "\n",
    "# Convert to Pandas DataFrame\n",
    "pandas_df = df.toPandas()\n",
    "\n",
    "# Separate features and target\n",
    "X = pandas_df.drop(\"final_target_column\", axis=1)\n",
    "y = pandas_df[\"final_target_column\"]\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Combine back into a DataFrame\n",
    "resampled_df = pd.concat([pd.DataFrame(X_resampled), pd.Series(y_resampled, name=\"final_target_column\")], axis=1)\n",
    "\n",
    "# Convert back to PySpark DataFrame\n",
    "df = spark.createDataFrame(resampled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "majority_df = df.filter(col(\"final_target_column\") == 0)\n",
    "minority_df = df.filter(col(\"final_target_column\") == 1)\n",
    "\n",
    "sampled_majority_df = majority_df.sample(False, fraction=minority_df.count() / majority_df.count())\n",
    "\n",
    "balanced_df = sampled_majority_df.union(minority_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Count: 42001\n",
      "+-------------------+--------------------------+------------------+------------------+------------------+----------+-------+-----------------+------------------+------------------+------------------+------------------+-------------------+-------------------+------------------+----+---------+-----+------------+------------------+--------------------+---------------+-------------------+--------------------+\n",
      "|               Date|BGT North of NE 70th Total|         Ped South|         Ped North|        Bike North|Bike South|Anomaly|Anomaly_3hr_Ahead|         Lag_1_day|         Lag_2_day|         Lag_3_day|   Rolling_Mean_3H|     Rolling_Std_3H|     Bike_Ped_Ratio|      class_weight|Hour|DayOfWeek|Month|Week of year|  Rolling_7Day_Avg|             Z-Score|z-score_anomaly|final_target_column|           features1|\n",
      "+-------------------+--------------------------+------------------+------------------+------------------+----------+-------+-----------------+------------------+------------------+------------------+------------------+-------------------+-------------------+------------------+----+---------+-----+------------+------------------+--------------------+---------------+-------------------+--------------------+\n",
      "|2014-01-01 00:00:00|         2.772588722239781|               0.0|1.4142135623730951|1.0986122886681096|      11.0|      0|              0.0|               0.0|               0.0|               0.0| 2.772588722239781|                0.0|0.45506010975607675|1.0095228952673514|   0|        4|    1|           1| 2.772588722239781|-0.13760363916302273|              0|                0.0|(10,[3,6,7,8,9],[...|\n",
      "|2014-01-01 01:00:00|         2.302585092994046|0.6931471805599453|               0.0|0.6931471805599453|       7.0|      0|              0.0| 2.772588722239781|               0.0|               0.0|2.5375869076169133|0.33234275342194736| 0.6931471805599453|1.0095228952673514|   1|        4|    1|           1|2.5375869076169133|-0.39565125561676723|              0|                0.0|[2.77258872223978...|\n",
      "|2014-01-01 03:00:00|         2.995732273553991|               0.0|               0.0|               0.0|      19.0|      0|              0.0| 2.302585092994046| 2.302585092994046| 2.772588722239781| 2.593372795445466|0.34791113512622784|                0.0|1.0095228952673514|   3|        4|    1|           1| 2.593372795445466|-0.01509041168845...|              0|                0.0|[2.30258509299404...|\n",
      "|2014-01-01 04:00:00|         2.995732273553991|               0.0|               0.0|               0.0|      19.0|      0|              0.0| 2.995732273553991| 2.302585092994046| 2.302585092994046| 2.649158683274018| 0.4001887112843144|                0.0|1.0095228952673514|   4|        4|    1|           1| 2.673844691067171|-0.01509041168845...|              0|                0.0|[2.99573227355399...|\n",
      "|2014-01-01 05:00:00|          2.70805020110221|               0.0|               0.0|               0.0|      14.0|      0|              0.0| 2.995732273553991| 2.995732273553991| 2.302585092994046|2.7505249603010595|0.32797737871051796|                0.0|1.0095228952673514|   5|        4|    1|           1|2.6795456094063437| -0.1730374326759075|              0|                0.0|[2.99573227355399...|\n",
      "|2014-01-01 07:00:00|        2.3978952727983707|1.0986122886681096|1.7320508075688772|1.6094379124341003|       1.0|      0|              0.0|2.3978952727983707|  2.70805020110221| 2.995732273553991|2.6248932550632356|0.28722396790330457| 0.5890951617646756|1.0095228952673514|   7|        4|    1|           1|2.5857822113992888| -0.3433227985753752|              0|                0.0|[2.39789527279837...|\n",
      "|2014-01-01 09:00:00|        3.4011973816621555| 1.791759469228055|3.7416573867739413|2.1972245773362196|       2.0|      0|              0.0| 3.332204510175204|2.3978952727983707|2.3978952727983707|2.8822981093585254| 0.5600489384652328| 0.4633874609888537|1.0095228952673514|   9|        4|    1|           1|2.8898153122348984| 0.20752341125240598|              0|                0.0|[3.33220451017520...|\n",
      "|2014-01-01 10:00:00|        4.2626798770413155|  2.70805020110221|               4.0| 3.713572066704308|       0.0|      0|              0.0|3.4011973816621555| 3.332204510175204|2.3978952727983707| 3.348494260419262| 0.7621060188399563| 0.7427144133408616|1.0095228952673514|  10|        4|    1|           1|3.0708078270188026|    0.68050593886814|              0|                0.0|[3.40119738166215...|\n",
      "|2014-01-01 11:00:00|          4.68213122712422| 3.044522437723423| 6.244997998398398|3.8712010109078907|       1.0|      0|              0.0|4.2626798770413155|3.4011973816621555| 3.332204510175204|3.9195532490007237| 0.6615467738045623| 0.5343274093055196|1.0095228952673514|  11|        4|    1|           1|3.3117219632431207|  0.9107986735878704|              0|                0.0|[4.26267987704131...|\n",
      "|2014-01-01 12:00:00|         4.844187086458591|3.6109179126442243|5.5677643628300215|   4.0943445622221|       0.0|      0|              0.0|  4.68213122712422|4.2626798770413155|3.4011973816621555|  4.29754889307157| 0.6458531222137303| 0.6234000393488333|1.0095228952673514|  12|        4|    1|           1|3.6168843754368893|  0.9997727274706197|              0|                0.0|[4.68213122712422...|\n",
      "|2014-01-01 14:00:00|        4.7535901911063645| 2.833213344056216|  4.47213595499958|4.3694478524670215|       1.0|      0|              0.0| 4.634728988229636| 4.844187086458591|  4.68213122712422| 4.728659373229703|0.09120669531375704| 0.7984903680024443|1.0095228952673514|  14|        4|    1|           1| 4.272959894542498|  0.9500320202738071|              0|                0.0|[4.63472898822963...|\n",
      "|2014-01-01 15:00:00|          4.61512051684126| 3.258096538021482| 4.123105625617661|  4.07753744390572|       0.0|      0|              0.0|4.7535901911063645| 4.634728988229636| 4.844187086458591| 4.711906695658962|0.10733060842865409| 0.7959112581080381|1.0095228952673514|  15|        4|    1|           1| 4.456233609780506|  0.8740075660529338|              0|                0.0|[4.75359019110636...|\n",
      "|2014-01-01 16:00:00|        3.9318256327243257|2.9444389791664403| 3.872983346207417|2.8903717578961645|       0.0|      0|              0.0|  4.61512051684126|4.7535901911063645| 4.634728988229636|4.4838163322253966| 0.3730447184592848| 0.5931421374845669|1.0095228952673514|  16|        4|    1|           1|  4.53203764564653| 0.49885596038474783|              0|                0.0|[4.61512051684126...|\n",
      "|2014-01-01 17:00:00|        2.9444389791664403|1.9459101490553132|1.7320508075688772| 2.302585092994046|       0.0|      0|              0.0|3.9318256327243257|  4.61512051684126|4.7535901911063645| 4.061243829959597| 0.8266649890967381| 0.8428046384111749|1.0095228952673514|  17|        4|    1|           1| 4.343717517378691|-0.04325213541388363|              0|                0.0|[3.93182563272432...|\n",
      "|2014-01-01 18:00:00|        1.3862943611198906|0.6931471805599453|               1.0|               0.0|       1.0|      0|              0.0|2.9444389791664403|3.9318256327243257|  4.61512051684126| 3.219419872462979| 1.4013643218885559|                0.0|1.0095228952673514|  18|        4|    1|           1|3.8728836793780728| -0.8987253270196496|              0|                0.0|[2.94443897916644...|\n",
      "|2014-01-01 20:00:00|        1.0986122886681096|               0.0|               0.0|               0.0|       2.0|      0|              0.0| 2.833213344056216|1.3862943611198906|2.9444389791664403|2.0656397432526643| 0.9588377644903533|                0.0|1.0095228952673514|  20|        4|    1|           1|3.0804421876689436| -1.0566723480071032|              0|                0.0|[2.83321334405621...|\n",
      "|2014-01-01 21:00:00|        1.9459101490553132|1.0986122886681096|               0.0|0.6931471805599453|       3.0|      0|              0.0|1.0986122886681096| 2.833213344056216|1.3862943611198906|1.8160075357248826| 0.7639571755846497| 0.6931471805599453|1.0095228952673514|  21|        4|    1|           1| 2.679345038804508|   -0.59147765653173|              0|                0.0|[1.09861228866810...|\n",
      "|2014-01-01 22:00:00|         3.044522437723423|1.3862943611198906|1.4142135623730951|               0.0|      15.0|      0|              0.0|1.9459101490553132|1.0986122886681096| 2.833213344056216|2.2305645548757655| 0.8921989803992059|                0.0|1.0095228952673514|  22|        4|    1|           1|2.4549738846448173|0.011697010337443263|              0|                0.0|[1.94591014905531...|\n",
      "|2014-01-02 00:00:00|        3.1354942159291497|               0.0|               0.0|               0.0|      22.0|      0|              0.0|2.8903717578961645| 3.044522437723423|1.9459101490553132|2.7540746401510123| 0.5481932642402204|                0.0|1.0095228952673514|   0|        5|    1|           1| 2.333488364921181|0.061643540682792666|              0|                0.0|[2.89037175789616...|\n",
      "|2014-01-02 01:00:00|        4.1588830833596715|               0.0|               0.0|               0.0|      63.0|      0|              0.0|3.1354942159291497|2.8903717578961645| 3.044522437723423|3.3073178737271025|  0.576654772611395|                0.0|1.0095228952673514|   1|        5|    1|           1|2.7295724680982927|  0.6235180486936039|              0|                0.0|[3.13549421592914...|\n",
      "+-------------------+--------------------------+------------------+------------------+------------------+----------+-------+-----------------+------------------+------------------+------------------+------------------+-------------------+-------------------+------------------+----+---------+-----+------------+------------------+--------------------+---------------+-------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "xgb modeled\n",
      "Accuracy: 0.9924\n",
      "Precision: 0.9944\n",
      "Recall: 0.9924\n",
      "F1 Score: 0.9932\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "\n",
    "# Define feature columns\n",
    "feature_columns = ['Lag_1_day', 'Lag_2_day', 'Lag_3_day', 'Rolling_Mean_3H', 'Rolling_Std_3H','Hour','DayOfWeek','Month','Rolling_7Day_Avg','Z-Score']\n",
    "\n",
    "# Drop existing feature columns if present\n",
    "if \"features\" in df.columns:\n",
    "    df = df.drop(\"features\")\n",
    "if \"features1\" in df.columns:\n",
    "    df = df.drop(\"features1\")\n",
    "\n",
    "# Assemble feature columns into a single vector\n",
    "vector_assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features1\")\n",
    "df = vector_assembler.transform(df)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "train_df, test_df = df.randomSplit([0.8, 0.2], seed=42)\n",
    "print(f\"Training Data Count: {train_df.count()}\")\n",
    "train_df.show()\n",
    "\n",
    "# Define Random Forest model\n",
    "# rf = RandomForestClassifier(featuresCol=\"features1\", labelCol=\"final_target_column\", numTrees=100, weightCol=\"class_weight\")\n",
    "\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "\n",
    "\n",
    "# Define GBT model with regularization-like hyperparameters\n",
    "xgb = GBTClassifier(\n",
    "    featuresCol=\"features1\",\n",
    "    labelCol=\"final_target_column\",\n",
    "    maxIter=100,  # Number of trees\n",
    "    maxDepth=5,  # Regularization: Limit tree depth\n",
    "    minInstancesPerNode=10,  # Regularization: Prevent overly specific splits\n",
    "    subsamplingRate=0.8,  # Regularization: Introduce randomness\n",
    "    stepSize=0.1,  # Regularization: Shrinkage (learning rate)\n",
    "    maxBins=32,  # Regularization: Coarsen feature space\n",
    "    weightCol='class_weight'\n",
    ")\n",
    "\n",
    "# Define hyperparameter grid for tuning\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(xgb.maxIter, [5, 10]) \\\n",
    "    .addGrid(xgb.maxDepth, [5, 10]) \\\n",
    "    .addGrid(xgb.minInstancesPerNode, [10, 20]) \\\n",
    "    .addGrid(xgb.subsamplingRate, [0.8, 1.0]) \\\n",
    "    .addGrid(xgb.stepSize, [0.1, 0.2]) \\\n",
    "    .addGrid(xgb.maxBins, [32, 64]) \\\n",
    "    .build()\n",
    "\n",
    "# xgb = GBTClassifier(featuresCol=\"features1\", labelCol=\"final_target_column\",maxIter=100,weightCol='class_weight')\n",
    "\n",
    "print('xgb modeled')\n",
    "# Define hyperparameter grid for tuning\n",
    "# paramGrid = ParamGridBuilder() \\\n",
    "#     .addGrid(rf.numTrees, [50, 100, 150]) \\\n",
    "#     .addGrid(rf.maxDepth, [5, 10, 15]) \\\n",
    "#     .build()\n",
    "\n",
    "# paramGrid = ParamGridBuilder() \\\n",
    "#     .addGrid(xgb.maxIter, [10, 15]).addGrid(xgb.maxDepth, [5, 10,15]).addGrid(xgb.stepSize, [0.05,0.1, 0.2]).addGrid(xgb.subsamplingRate, [0.8, 1]).addGrid(xgb.maxBins, [16, 32]).build()\n",
    "\n",
    "# Perform cross-validation\n",
    "crossval = CrossValidator(estimator=xgb, estimatorParamMaps=paramGrid,\n",
    "                          evaluator=BinaryClassificationEvaluator(labelCol=\"final_target_column\"), numFolds=3)\n",
    "# xgb_model = crossval.fit(train_df)\n",
    "xgb_model = xgb.fit(train_df)\n",
    "\n",
    "\n",
    "# Make predictions\n",
    "predictions = xgb_model.transform(test_df)\n",
    "\n",
    "# Define evaluators\n",
    "accuracy_evaluator = MulticlassClassificationEvaluator(labelCol=\"final_target_column\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "precision_evaluator = MulticlassClassificationEvaluator(labelCol=\"final_target_column\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "recall_evaluator = MulticlassClassificationEvaluator(labelCol=\"final_target_column\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "f1_evaluator = MulticlassClassificationEvaluator(labelCol=\"final_target_column\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "\n",
    "# Compute metrics\n",
    "accuracy = accuracy_evaluator.evaluate(predictions)\n",
    "precision = precision_evaluator.evaluate(predictions)\n",
    "recall = recall_evaluator.evaluate(predictions)\n",
    "f1_score = f1_evaluator.evaluate(predictions)\n",
    "\n",
    "# Print evaluation results\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+---+\n",
      "|final_target_column|  0.0|1.0|\n",
      "+-------------------+-----+---+\n",
      "|                0.0|10450| 59|\n",
      "|                1.0|   21| 50|\n",
      "+-------------------+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm = predictions.groupBy(\"final_target_column\").pivot(\"prediction\").count().fillna(0)\n",
    "cm.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictions.withColumn(\"adjusted_prediction\",\n",
    "                                     when(col(\"prob_anomaly\") > 0.45, 1).otherwise(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionRefusedError",
     "evalue": "[WinError 10061] No connection could be made because the target machine actively refused it",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionResetError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\lenovo\\anaconda3\\envs\\anomaly_detect\\lib\\site-packages\\py4j\\clientserver.py:503\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[1;34m(self, command)\u001b[0m\n\u001b[0;32m    502\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 503\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msendall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mConnectionResetError\u001b[0m: [WinError 10054] An existing connection was forcibly closed by the remote host",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mPy4JNetworkError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\lenovo\\anaconda3\\envs\\anomaly_detect\\lib\\site-packages\\py4j\\java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[1;34m(self, command, retry, binary)\u001b[0m\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1038\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1039\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m binary:\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\anaconda3\\envs\\anomaly_detect\\lib\\site-packages\\py4j\\clientserver.py:506\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[1;34m(self, command)\u001b[0m\n\u001b[0;32m    505\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError while sending or receiving.\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 506\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JNetworkError(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError while sending\u001b[39m\u001b[38;5;124m\"\u001b[39m, e, proto\u001b[38;5;241m.\u001b[39mERROR_ON_SEND)\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mPy4JNetworkError\u001b[0m: Error while sending",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[133], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupBy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfinal_target_column\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcount()\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\anaconda3\\envs\\anomaly_detect\\lib\\site-packages\\pyspark\\sql\\dataframe.py:3416\u001b[0m, in \u001b[0;36mDataFrame.groupBy\u001b[1;34m(self, *cols)\u001b[0m\n\u001b[0;32m   3347\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgroupBy\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mcols: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumnOrName\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGroupedData\u001b[39m\u001b[38;5;124m\"\u001b[39m:  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   3348\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Groups the :class:`DataFrame` using the specified columns,\u001b[39;00m\n\u001b[0;32m   3349\u001b[0m \u001b[38;5;124;03m    so we can run aggregation on them. See :class:`GroupedData`\u001b[39;00m\n\u001b[0;32m   3350\u001b[0m \u001b[38;5;124;03m    for all the available aggregate functions.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3414\u001b[0m \u001b[38;5;124;03m    +-----+---+-----+\u001b[39;00m\n\u001b[0;32m   3415\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3416\u001b[0m     jgd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jdf\u001b[38;5;241m.\u001b[39mgroupBy(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jcols\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcols\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   3417\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgroup\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GroupedData\n\u001b[0;32m   3419\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m GroupedData(jgd, \u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\anaconda3\\envs\\anomaly_detect\\lib\\site-packages\\pyspark\\sql\\dataframe.py:2766\u001b[0m, in \u001b[0;36mDataFrame._jcols\u001b[1;34m(self, *cols)\u001b[0m\n\u001b[0;32m   2764\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(cols) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(cols[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m   2765\u001b[0m     cols \u001b[38;5;241m=\u001b[39m cols[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m-> 2766\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jseq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_to_java_column\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\anaconda3\\envs\\anomaly_detect\\lib\\site-packages\\pyspark\\sql\\dataframe.py:2753\u001b[0m, in \u001b[0;36mDataFrame._jseq\u001b[1;34m(self, cols, converter)\u001b[0m\n\u001b[0;32m   2747\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_jseq\u001b[39m(\n\u001b[0;32m   2748\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   2749\u001b[0m     cols: Sequence,\n\u001b[0;32m   2750\u001b[0m     converter: Optional[Callable[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrimitiveType\u001b[39m\u001b[38;5;124m\"\u001b[39m, JavaObject]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2751\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m JavaObject:\n\u001b[0;32m   2752\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a JVM Seq of Columns from a list of Column or names\"\"\"\u001b[39;00m\n\u001b[1;32m-> 2753\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_to_seq\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconverter\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\anaconda3\\envs\\anomaly_detect\\lib\\site-packages\\pyspark\\sql\\column.py:88\u001b[0m, in \u001b[0;36m_to_seq\u001b[1;34m(sc, cols, converter)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;124;03mConvert a list of Columns (or names) into a JVM Seq of Column.\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \n\u001b[0;32m     84\u001b[0m \u001b[38;5;124;03mAn optional `converter` could be used to convert items in `cols`\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;124;03minto JVM Column objects.\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m converter:\n\u001b[1;32m---> 88\u001b[0m     cols \u001b[38;5;241m=\u001b[39m [converter(c) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m cols]\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m sc\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sc\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39mPythonUtils\u001b[38;5;241m.\u001b[39mtoSeq(cols)\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\anaconda3\\envs\\anomaly_detect\\lib\\site-packages\\pyspark\\sql\\column.py:88\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;124;03mConvert a list of Columns (or names) into a JVM Seq of Column.\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \n\u001b[0;32m     84\u001b[0m \u001b[38;5;124;03mAn optional `converter` could be used to convert items in `cols`\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;124;03minto JVM Column objects.\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m converter:\n\u001b[1;32m---> 88\u001b[0m     cols \u001b[38;5;241m=\u001b[39m [\u001b[43mconverter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m cols]\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m sc\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sc\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39mPythonUtils\u001b[38;5;241m.\u001b[39mtoSeq(cols)\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\anaconda3\\envs\\anomaly_detect\\lib\\site-packages\\pyspark\\sql\\column.py:63\u001b[0m, in \u001b[0;36m_to_java_column\u001b[1;34m(col)\u001b[0m\n\u001b[0;32m     61\u001b[0m     jcol \u001b[38;5;241m=\u001b[39m col\u001b[38;5;241m.\u001b[39m_jc\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(col, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m---> 63\u001b[0m     jcol \u001b[38;5;241m=\u001b[39m \u001b[43m_create_column_from_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[0;32m     66\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOT_COLUMN_OR_STR\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     67\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcol\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(col)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m},\n\u001b[0;32m     68\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\anaconda3\\envs\\anomaly_detect\\lib\\site-packages\\pyspark\\sql\\column.py:56\u001b[0m, in \u001b[0;36m_create_column_from_name\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_create_column_from_name\u001b[39m(name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     55\u001b[0m     sc \u001b[38;5;241m=\u001b[39m get_active_spark_context()\n\u001b[1;32m---> 56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mJVMView\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jvm\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctions\u001b[49m\u001b[38;5;241m.\u001b[39mcol(name)\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\anaconda3\\envs\\anomaly_detect\\lib\\site-packages\\py4j\\java_gateway.py:1712\u001b[0m, in \u001b[0;36mJVMView.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1709\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m UserHelpAutoCompletion\u001b[38;5;241m.\u001b[39mKEY:\n\u001b[0;32m   1710\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m UserHelpAutoCompletion()\n\u001b[1;32m-> 1712\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproto\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREFLECTION_COMMAND_NAME\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\n\u001b[0;32m   1714\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproto\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREFL_GET_UNKNOWN_SUB_COMMAND_NAME\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\n\u001b[0;32m   1715\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mproto\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEND_COMMAND_PART\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1716\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer \u001b[38;5;241m==\u001b[39m proto\u001b[38;5;241m.\u001b[39mSUCCESS_PACKAGE:\n\u001b[0;32m   1717\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m JavaPackage(name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gateway_client, jvm_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_id)\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\anaconda3\\envs\\anomaly_detect\\lib\\site-packages\\py4j\\java_gateway.py:1053\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[1;34m(self, command, retry, binary)\u001b[0m\n\u001b[0;32m   1051\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(retry, connection, pne):\n\u001b[0;32m   1052\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mException while sending command.\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m-> 1053\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbinary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbinary\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1054\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1055\u001b[0m     logging\u001b[38;5;241m.\u001b[39mexception(\n\u001b[0;32m   1056\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mException while sending command.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\anaconda3\\envs\\anomaly_detect\\lib\\site-packages\\py4j\\java_gateway.py:1036\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[1;34m(self, command, retry, binary)\u001b[0m\n\u001b[0;32m   1015\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msend_command\u001b[39m(\u001b[38;5;28mself\u001b[39m, command, retry\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, binary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Sends a command to the JVM. This method is not intended to be\u001b[39;00m\n\u001b[0;32m   1017\u001b[0m \u001b[38;5;124;03m       called directly by Py4J users. It is usually called by\u001b[39;00m\n\u001b[0;32m   1018\u001b[0m \u001b[38;5;124;03m       :class:`JavaMember` instances.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1034\u001b[0m \u001b[38;5;124;03m     if `binary` is `True`.\u001b[39;00m\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1036\u001b[0m     connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1037\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1038\u001b[0m         response \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39msend_command(command)\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\anaconda3\\envs\\anomaly_detect\\lib\\site-packages\\py4j\\clientserver.py:284\u001b[0m, in \u001b[0;36mJavaClient._get_connection\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m connection\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 284\u001b[0m     connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_new_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m connection\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\anaconda3\\envs\\anomaly_detect\\lib\\site-packages\\py4j\\clientserver.py:291\u001b[0m, in \u001b[0;36mJavaClient._create_new_connection\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_create_new_connection\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    288\u001b[0m     connection \u001b[38;5;241m=\u001b[39m ClientServerConnection(\n\u001b[0;32m    289\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjava_parameters, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_parameters,\n\u001b[0;32m    290\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_property, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 291\u001b[0m     \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect_to_java_server\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    292\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_thread_connection(connection)\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m connection\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\anaconda3\\envs\\anomaly_detect\\lib\\site-packages\\py4j\\clientserver.py:438\u001b[0m, in \u001b[0;36mClientServerConnection.connect_to_java_server\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mssl_context:\n\u001b[0;32m    436\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mssl_context\u001b[38;5;241m.\u001b[39mwrap_socket(\n\u001b[0;32m    437\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket, server_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjava_address)\n\u001b[1;32m--> 438\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjava_address\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjava_port\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    439\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket\u001b[38;5;241m.\u001b[39mmakefile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_connected \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mConnectionRefusedError\u001b[0m: [WinError 10061] No connection could be made because the target machine actively refused it"
     ]
    }
   ],
   "source": [
    "predictions.groupBy(\"final_target_column\").count().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------------+------------------+------------------+------------------+----------+-------+-----------------+------------------+------------------+------------------+-------------------+-------------------+-------------------+-----------------+----+---------+-----+------------+-------------------+--------------------+---------------+-------------------+--------------------+--------------------+--------------------+----------+\n",
      "|               Date|BGT North of NE 70th Total|         Ped South|         Ped North|        Bike North|Bike South|Anomaly|Anomaly_3hr_Ahead|         Lag_1_day|         Lag_2_day|         Lag_3_day|    Rolling_Mean_3H|     Rolling_Std_3H|     Bike_Ped_Ratio|     class_weight|Hour|DayOfWeek|Month|Week of year|   Rolling_7Day_Avg|             Z-Score|z-score_anomaly|final_target_column|           features1|       rawPrediction|         probability|prediction|\n",
      "+-------------------+--------------------------+------------------+------------------+------------------+----------+-------+-----------------+------------------+------------------+------------------+-------------------+-------------------+-------------------+-----------------+----+---------+-----+------------+-------------------+--------------------+---------------+-------------------+--------------------+--------------------+--------------------+----------+\n",
      "|2014-01-01 02:00:00|         2.302585092994046|               0.0|               0.0|               0.0|       9.0|      0|              0.0| 2.302585092994046| 2.772588722239781|               0.0|  2.459252969409291|0.27135672186512627|                0.0|1.009522346797727|   2|        4|    1|           1|  2.459252969409291|-0.39565125561676723|              0|                0.0|[2.30258509299404...|[148.309894594406...|[0.98873263062937...|       0.0|\n",
      "|2014-01-01 06:00:00|        2.3978952727983707|               0.0|               1.0|0.6931471805599453|       8.0|      0|              0.0|  2.70805020110221| 2.995732273553991| 2.995732273553991| 2.7743525052521405| 0.2852683222448084|0.34657359027997264|1.009522346797727|   6|        4|    1|           1|  2.639309847033776| -0.3433227985753752|              0|                0.0|[2.70805020110221...|[149.982485231004...|[0.99988323487336...|       0.0|\n",
      "|2014-01-01 08:00:00|         3.332204510175204|2.5649493574615367| 2.449489742783178|2.1972245773362196|       1.0|      0|              0.0|2.3978952727983707|2.3978952727983707|  2.70805020110221|  2.709011314218539|0.44043806438704336| 0.6369708974879909|1.009522346797727|   8|        4|    1|           1|  2.732870699568026| 0.16964403132489678|              0|                0.0|[2.39789527279837...|[149.982485231004...|[0.99988323487336...|       0.0|\n",
      "|2014-01-01 13:00:00|         4.634728988229636| 3.091042453358316|               4.0| 4.189654742026425|       0.0|      0|              0.0| 4.844187086458591|  4.68213122712422|4.2626798770413155|   4.60593179471344| 0.2457797760084507|  0.837930948405285|1.009522346797727|  13|        4|    1|           1|  3.936432049069928|  0.8847732686756818|              0|                0.0|[4.84418708645859...|[149.982485231004...|[0.99988323487336...|       0.0|\n",
      "|2014-01-01 19:00:00|         2.833213344056216| 1.791759469228055|1.7320508075688772|1.6094379124341003|       4.0|      0|              0.0|1.3862943611198906|2.9444389791664403|3.9318256327243257| 2.7739430792667186| 1.0486249391062685| 0.5890951617646756|1.009522346797727|  19|        4|    1|           1| 3.5856017161777336|-0.10431870648442539|              0|                0.0|[1.38629436111989...|[149.982485231004...|[0.99988323487336...|       0.0|\n",
      "|2014-01-01 23:00:00|        2.8903717578961645|               0.0|               0.0|0.6931471805599453|      16.0|      0|              0.0| 3.044522437723423|1.9459101490553132|1.0986122886681096| 2.2448541583357526|  0.905428125780821| 0.6931471805599453|1.009522346797727|  23|        4|    1|           1| 2.3061947596693657|-0.07293683720961652|              0|                0.0|[3.04452243772342...|[149.982485231004...|[0.99988323487336...|       0.0|\n",
      "|2014-01-02 05:00:00|         3.912023005428146|0.6931471805599453|               0.0|               0.0|      48.0|      0|              0.0| 4.304065093204169| 3.970291913552122|   4.0943445622221|  4.070181143601634|0.17347183021218718|                0.0|1.009522346797727|   5|        5|    1|           1| 3.7807819473702176| 0.48798365971442825|              0|                0.0|[4.30406509320416...|[149.982485231004...|[0.99988323487336...|       0.0|\n",
      "|2014-01-02 11:00:00|         2.995732273553991| 2.302585092994046|               0.0| 2.302585092994046|       1.0|      0|              0.0|  2.70805020110221|3.4011973816621555| 2.833213344056216|  2.984548300093643| 0.3017035002000986|  2.302585092994046|1.009522346797727|  11|        5|    1|           1|  2.983881258316621|-0.01509041168845...|              0|                0.0|[2.70805020110221...|[149.982485231004...|[0.99988323487336...|       0.0|\n",
      "|2014-01-02 21:00:00|        1.0986122886681096|0.6931471805599453|               1.0|               0.0|       0.0|      0|              0.0|1.9459101490553132|  2.70805020110221|3.4657359027997265| 2.3045771354063396| 1.0155578789517683|                0.0|1.009522346797727|  21|        5|    1|           1|  3.040223010476761| -1.0566723480071032|              0|                0.0|[1.94591014905531...|[149.982485231004...|[0.99988323487336...|       0.0|\n",
      "|2014-01-02 22:00:00|        0.6931471805599453|0.6931471805599453|               0.0|               0.0|       0.0|      0|              0.0|1.0986122886681096|1.9459101490553132|  2.70805020110221| 1.6114299548463946| 0.8982720777715332|                0.0|1.009522346797727|  22|        5|    1|           1| 2.5407219302672637|  -1.279286170947963|              0|                0.0|[1.09861228866810...|[149.982485231004...|[0.99988323487336...|       0.0|\n",
      "|2014-01-02 23:00:00|                       0.0|               0.0|               0.0|               0.0|       0.0|      0|              0.0|0.6931471805599453|1.0986122886681096|1.9459101490553132|  0.934417404570842| 0.8126960766624506|                0.0|1.009522346797727|  23|        5|    1|           1| 1.9317676621185043| -1.6598470148762765|              0|                0.0|[0.69314718055994...|[149.982485231004...|[0.99988323487336...|       0.0|\n",
      "|2014-01-03 01:00:00|        0.6931471805599453|               0.0|               0.0|0.6931471805599453|       0.0|      0|              0.0|               0.0|               0.0|0.6931471805599453|0.34657359027997264|0.40018871128431455| 0.6931471805599453|1.009522346797727|   1|        6|    1|           1| 1.0198381428493606|  -1.279286170947963|              0|                0.0|[0.0,0.0,0.693147...|[149.837861087307...|[0.99891907391537...|       0.0|\n",
      "|2014-01-03 03:00:00|        1.3862943611198906|0.6931471805599453|               1.0|               0.0|       1.0|      0|              0.0|1.0986122886681096|0.6931471805599453|               0.0| 0.7945134575869863| 0.6011676120285359|                0.0|1.009522346797727|   3|        6|    1|           1| 0.7099733285108573| -0.8987253270196496|              0|                0.0|[1.09861228866810...|[149.880609977942...|[0.99920406651961...|       0.0|\n",
      "|2014-01-03 07:00:00|        3.6109179126442243|0.6931471805599453|2.6457513110645907|1.3862943611198906|      25.0|      0|              0.0| 2.833213344056216| 1.791759469228055|2.1972245773362196|  2.608278825816179| 0.7940508234799926| 0.3802492937224181|1.009522346797727|   7|        6|    1|           1| 1.9444527333732373|  0.3226669543526694|              0|                0.0|[2.83321334405621...|[149.982485231004...|[0.99988323487336...|       0.0|\n",
      "|2014-01-03 14:00:00|         4.624972813284271|2.9444389791664403|3.4641016151377544| 3.713572066704308|      31.0|      0|              0.0|  4.51085950651685| 4.343805421853684| 4.276666119016055|  4.439075965167715|0.15828660661244504| 0.8318744479542305|1.009522346797727|  14|        6|    1|           1|  4.228123230513585|   0.879416804313061|              0|                0.0|[4.51085950651685...|[149.982485231004...|[0.99988323487336...|       0.0|\n",
      "|2014-01-03 21:00:00|         1.791759469228055|0.6931471805599453|               1.0|1.3862943611198906|       0.0|      0|              0.0|2.1972245773362196|2.1972245773362196|3.6635616461296463|  2.462442567507535| 0.8232423749963342| 0.6931471805599453|1.009522346797727|  21|        6|    1|           1|  3.351907239011343| -0.6761115040787897|              0|                0.0|[2.19722457733621...|[149.982485231004...|[0.99988323487336...|       0.0|\n",
      "|2014-01-04 05:00:00|        1.3862943611198906|0.6931471805599453|               1.0|0.6931471805599453|       0.0|      0|              0.0|0.6931471805599453|               0.0|0.6931471805599453| 0.6931471805599453| 0.5659523030068886|0.34657359027997264|1.009522346797727|   5|        7|    1|           1|0.39608410317711157| -0.8987253270196496|              0|                0.0|[0.69314718055994...|[149.947092429575...|[0.99964728286383...|       0.0|\n",
      "|2014-01-05 04:00:00|        0.6931471805599453|               0.0|               0.0|0.6931471805599453|       0.0|      0|              0.0|               0.0|               0.0|               0.0|0.17328679513998632|0.34657359027997264| 0.6931471805599453|1.009522346797727|   4|        1|    1|           1| 0.5530287158439844|  -1.279286170947963|              0|                0.0|[0.0,0.0,0.0,0.17...|[149.542172462602...|[0.99694781641735...|       0.0|\n",
      "|2014-01-05 16:00:00|         4.394449154672439|3.2188758248682006|3.7416573867739413|2.4849066497880004|      31.0|      0|              0.0| 5.030437921392435| 5.075173815233827|  5.19295685089021|  4.923254435547228|0.35913888468817246| 0.5240586670642277|1.009522346797727|  16|        1|    1|           1| 4.7728379008490105|  0.7528516526004169|              0|                0.0|[5.03043792139243...|[149.982485231004...|[0.99988323487336...|       0.0|\n",
      "|2014-01-05 20:00:00|        1.9459101490553132|1.0986122886681096|1.4142135623730951|1.0986122886681096|       0.0|      0|              0.0|0.6931471805599453|1.6094379124341003| 2.995732273553991| 1.8110568789008374| 0.9507915117507273|0.45506010975607675|1.009522346797727|  20|        1|    1|           1| 3.1063269152717212|   -0.59147765653173|              0|                0.0|[0.69314718055994...|[149.982485231004...|[0.99988323487336...|       0.0|\n",
      "+-------------------+--------------------------+------------------+------------------+------------------+----------+-------+-----------------+------------------+------------------+------------------+-------------------+-------------------+-------------------+-----------------+----+---------+-----+------------+-------------------+--------------------+---------------+-------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+-------------------+\n",
      "|Anomaly_3hr_Ahead|        prob_anomaly|adjusted_prediction|\n",
      "+-----------------+--------------------+-------------------+\n",
      "|              0.0|0.033107198019176054|                  0|\n",
      "|              0.0|0.033107198019176054|                  0|\n",
      "|              0.0|0.033107198019176054|                  0|\n",
      "|              0.0|0.032817874193661334|                  0|\n",
      "|              0.0|0.032817874193661334|                  0|\n",
      "|              0.0|0.032817874193661334|                  0|\n",
      "|              0.0|0.033107198019176054|                  0|\n",
      "|              0.0|0.033073281122545484|                  0|\n",
      "|              0.0|0.032817874193661334|                  0|\n",
      "|              0.0|0.032817874193661334|                  0|\n",
      "+-----------------+--------------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o76460.collectToPython.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 102844.0 failed 1 times, most recent failure: Lost task 0.0 in stage 102844.0 (TID 67774) (192.168.1.90 executor driver): org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:203)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.base/sun.nio.ch.NioSocketImpl.timedAccept(NioSocketImpl.java:701)\r\n\tat java.base/sun.nio.ch.NioSocketImpl.accept(NioSocketImpl.java:745)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:698)\r\n\tat java.base/java.net.ServerSocket.platformImplAccept(ServerSocket.java:663)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:639)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:585)\r\n\tat java.base/java.net.ServerSocket.accept(ServerSocket.java:543)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:190)\r\n\t... 32 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2393)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2414)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2433)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:530)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:483)\r\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:61)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$collectToPython$1(Dataset.scala:4149)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4323)\r\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4321)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\r\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:4321)\r\n\tat org.apache.spark.sql.Dataset.collectToPython(Dataset.scala:4146)\r\n\tat jdk.internal.reflect.GeneratedMethodAccessor261.invoke(Unknown Source)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\nCaused by: org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:203)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\t... 1 more\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.base/sun.nio.ch.NioSocketImpl.timedAccept(NioSocketImpl.java:701)\r\n\tat java.base/sun.nio.ch.NioSocketImpl.accept(NioSocketImpl.java:745)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:698)\r\n\tat java.base/java.net.ServerSocket.platformImplAccept(ServerSocket.java:663)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:639)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:585)\r\n\tat java.base/java.net.ServerSocket.accept(ServerSocket.java:543)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:190)\r\n\t... 32 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[78], line 63\u001b[0m\n\u001b[0;32m     59\u001b[0m threshold_df \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39mcreateDataFrame(results, schema\u001b[38;5;241m=\u001b[39mschema)\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m#  Show the final DataFrame\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# threshold_df.show()/\u001b[39;00m\n\u001b[1;32m---> 63\u001b[0m \u001b[43mthreshold_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoPandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Convert small subset to Pandas for safe display\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\anaconda3\\envs\\anomaly_detect\\lib\\site-packages\\pyspark\\sql\\pandas\\conversion.py:202\u001b[0m, in \u001b[0;36mPandasConversionMixin.toPandas\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    199\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;66;03m# Below is toPandas without Arrow optimization.\u001b[39;00m\n\u001b[1;32m--> 202\u001b[0m rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(rows) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    204\u001b[0m     pdf \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39mfrom_records(\n\u001b[0;32m    205\u001b[0m         rows, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(rows)), columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    206\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\anaconda3\\envs\\anomaly_detect\\lib\\site-packages\\pyspark\\sql\\dataframe.py:1263\u001b[0m, in \u001b[0;36mDataFrame.collect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1243\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns all the records as a list of :class:`Row`.\u001b[39;00m\n\u001b[0;32m   1244\u001b[0m \n\u001b[0;32m   1245\u001b[0m \u001b[38;5;124;03m.. versionadded:: 1.3.0\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1260\u001b[0m \u001b[38;5;124;03m[Row(age=14, name='Tom'), Row(age=23, name='Alice'), Row(age=16, name='Bob')]\u001b[39;00m\n\u001b[0;32m   1261\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1262\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SCCallSiteSync(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sc):\n\u001b[1;32m-> 1263\u001b[0m     sock_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollectToPython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1264\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_load_from_socket(sock_info, BatchedSerializer(CPickleSerializer())))\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\anaconda3\\envs\\anomaly_detect\\lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\anaconda3\\envs\\anomaly_detect\\lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\anaconda3\\envs\\anomaly_detect\\lib\\site-packages\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o76460.collectToPython.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 102844.0 failed 1 times, most recent failure: Lost task 0.0 in stage 102844.0 (TID 67774) (192.168.1.90 executor driver): org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:203)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.base/sun.nio.ch.NioSocketImpl.timedAccept(NioSocketImpl.java:701)\r\n\tat java.base/sun.nio.ch.NioSocketImpl.accept(NioSocketImpl.java:745)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:698)\r\n\tat java.base/java.net.ServerSocket.platformImplAccept(ServerSocket.java:663)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:639)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:585)\r\n\tat java.base/java.net.ServerSocket.accept(ServerSocket.java:543)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:190)\r\n\t... 32 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2393)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2414)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2433)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:530)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:483)\r\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:61)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$collectToPython$1(Dataset.scala:4149)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4323)\r\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4321)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\r\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:4321)\r\n\tat org.apache.spark.sql.Dataset.collectToPython(Dataset.scala:4146)\r\n\tat jdk.internal.reflect.GeneratedMethodAccessor261.invoke(Unknown Source)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\nCaused by: org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:203)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\t... 1 more\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.base/sun.nio.ch.NioSocketImpl.timedAccept(NioSocketImpl.java:701)\r\n\tat java.base/sun.nio.ch.NioSocketImpl.accept(NioSocketImpl.java:745)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:698)\r\n\tat java.base/java.net.ServerSocket.platformImplAccept(ServerSocket.java:663)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:639)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:585)\r\n\tat java.base/java.net.ServerSocket.accept(ServerSocket.java:543)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:190)\r\n\t... 32 more\r\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pyspark.sql.functions import col, when, expr\n",
    "from pyspark.ml.functions import vector_to_array\n",
    "\n",
    "# Convert probability vector to an array\n",
    "predictions = predictions.withColumn(\"probability_array\", vector_to_array(col(\"probability\")))\n",
    "\n",
    "# Extract probability of anomaly (second value in array)\n",
    "predictions = predictions.withColumn(\"prob_anomaly\", col(\"probability_array\")[1])\n",
    "\n",
    "# Apply a fixed threshold for reference\n",
    "threshold = 0.99\n",
    "predictions = predictions.withColumn(\"adjusted_prediction\", when(col(\"prob_anomaly\") > threshold, 1).otherwise(0))\n",
    "\n",
    "# Show updated results\n",
    "predictions.select(\"Anomaly_3hr_Ahead\", \"prob_anomaly\", \"adjusted_prediction\").show(10)\n",
    "\n",
    "# Define multiple threshold values to test\n",
    "thresholds = np.arange(0.4, 0.9, 0.05)  # From 0.4 to 0.85 with step 0.05\n",
    "\n",
    "results = []\n",
    "\n",
    "for t in thresholds:\n",
    "    #  Apply threshold\n",
    "    predictions_temp = predictions.withColumn(\"prediction\", when(col(\"prob_anomaly\") > t, 1).otherwise(0))\n",
    "\n",
    "    #  Compute confusion matrix\n",
    "    cm = predictions_temp.groupBy(\"Anomaly_3hr_Ahead\").pivot(\"prediction\").count().fillna(0)\n",
    "    cm_values = cm.collect()\n",
    "\n",
    "    #  Convert to dictionary for safe indexing\n",
    "    cm_dict = {row[\"Anomaly_3hr_Ahead\"]: row.asDict() for row in cm_values}\n",
    "\n",
    "\n",
    "    TN = cm_dict.get(0, {}).get(0.0, 0) if cm_dict.get(0) else 0\n",
    "    FP = cm_dict.get(0, {}).get(1.0, 0) if cm_dict.get(0) else 0\n",
    "    FN = cm_dict.get(1, {}).get(0.0, 0) if cm_dict.get(1) else 0\n",
    "    TP = cm_dict.get(1, {}).get(1.0, 0) if cm_dict.get(1) else 0\n",
    "\n",
    "\n",
    "    #  Compute Precision, Recall, and F1 Score\n",
    "    precision = TP / max(TP + FP, 1e-6)\n",
    "    recall = TP / max(TP + FN, 1e-6)\n",
    "    f1_score = 2 * (precision * recall) / max(precision + recall, 1e-6)\n",
    "\n",
    "    results.append((float(t), float(precision), float(recall), float(f1_score)))\n",
    "\n",
    "#  Define schema for DataFrame\n",
    "from pyspark.sql.types import StructType, StructField, DoubleType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"Threshold\", DoubleType(), True),\n",
    "    StructField(\"Precision\", DoubleType(), True),\n",
    "    StructField(\"Recall\", DoubleType(), True),\n",
    "    StructField(\"F1_Score\", DoubleType(), True)\n",
    "])\n",
    "\n",
    "#  Convert results to DataFrame\n",
    "threshold_df = spark.createDataFrame(results, schema=schema)\n",
    "\n",
    "#  Show the final DataFrame\n",
    "# threshold_df.show()/\n",
    "threshold_df.limit(5).toPandas()  # Convert small subset to Pandas for safe display\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o76467.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 102845.0 failed 1 times, most recent failure: Lost task 0.0 in stage 102845.0 (TID 67775) (192.168.1.90 executor driver): org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:203)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.base/sun.nio.ch.NioSocketImpl.timedAccept(NioSocketImpl.java:701)\r\n\tat java.base/sun.nio.ch.NioSocketImpl.accept(NioSocketImpl.java:745)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:698)\r\n\tat java.base/java.net.ServerSocket.platformImplAccept(ServerSocket.java:663)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:639)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:585)\r\n\tat java.base/java.net.ServerSocket.accept(ServerSocket.java:543)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:190)\r\n\t... 37 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\nCaused by: org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:203)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.base/sun.nio.ch.NioSocketImpl.timedAccept(NioSocketImpl.java:701)\r\n\tat java.base/sun.nio.ch.NioSocketImpl.accept(NioSocketImpl.java:745)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:698)\r\n\tat java.base/java.net.ServerSocket.platformImplAccept(ServerSocket.java:663)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:639)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:585)\r\n\tat java.base/java.net.ServerSocket.accept(ServerSocket.java:543)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:190)\r\n\t... 37 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[79], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# threshold_df.show()\u001b[39;00m\n\u001b[0;32m      2\u001b[0m threshold_df \u001b[38;5;241m=\u001b[39m threshold_df\u001b[38;5;241m.\u001b[39mrepartition(\u001b[38;5;241m4\u001b[39m)  \u001b[38;5;66;03m# Reduce parallelism\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mthreshold_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtruncate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\anaconda3\\envs\\anomaly_detect\\lib\\site-packages\\pyspark\\sql\\dataframe.py:947\u001b[0m, in \u001b[0;36mDataFrame.show\u001b[1;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mshow\u001b[39m(\u001b[38;5;28mself\u001b[39m, n: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m, truncate: Union[\u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, vertical: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    888\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Prints the first ``n`` rows to the console.\u001b[39;00m\n\u001b[0;32m    889\u001b[0m \n\u001b[0;32m    890\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    945\u001b[0m \u001b[38;5;124;03m    name | Bob\u001b[39;00m\n\u001b[0;32m    946\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_show_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\anaconda3\\envs\\anomaly_detect\\lib\\site-packages\\pyspark\\sql\\dataframe.py:978\u001b[0m, in \u001b[0;36mDataFrame._show_string\u001b[1;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[0;32m    969\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m    970\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[0;32m    971\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOT_BOOL\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    972\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    975\u001b[0m         },\n\u001b[0;32m    976\u001b[0m     )\n\u001b[1;32m--> 978\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshowString\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mint_truncate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\anaconda3\\envs\\anomaly_detect\\lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\anaconda3\\envs\\anomaly_detect\\lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\anaconda3\\envs\\anomaly_detect\\lib\\site-packages\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o76467.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 102845.0 failed 1 times, most recent failure: Lost task 0.0 in stage 102845.0 (TID 67775) (192.168.1.90 executor driver): org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:203)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.base/sun.nio.ch.NioSocketImpl.timedAccept(NioSocketImpl.java:701)\r\n\tat java.base/sun.nio.ch.NioSocketImpl.accept(NioSocketImpl.java:745)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:698)\r\n\tat java.base/java.net.ServerSocket.platformImplAccept(ServerSocket.java:663)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:639)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:585)\r\n\tat java.base/java.net.ServerSocket.accept(ServerSocket.java:543)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:190)\r\n\t... 37 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\nCaused by: org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:203)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.base/sun.nio.ch.NioSocketImpl.timedAccept(NioSocketImpl.java:701)\r\n\tat java.base/sun.nio.ch.NioSocketImpl.accept(NioSocketImpl.java:745)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:698)\r\n\tat java.base/java.net.ServerSocket.platformImplAccept(ServerSocket.java:663)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:639)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:585)\r\n\tat java.base/java.net.ServerSocket.accept(ServerSocket.java:543)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:190)\r\n\t... 37 more\r\n"
     ]
    }
   ],
   "source": [
    "# threshold_df.show()\n",
    "threshold_df = threshold_df.repartition(4)  # Reduce parallelism\n",
    "threshold_df.limit(10).show(truncate = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+---+\n",
      "|final_target_column|  0.0|1.0|\n",
      "+-------------------+-----+---+\n",
      "|                0.0|10417| 92|\n",
      "|                1.0|   14| 57|\n",
      "+-------------------+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm = predictions.groupBy(\"final_target_column\").pivot(\"prediction\").count().fillna(0)\n",
    "cm.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert PySpark DataFrame to Pandas DataFrame\n",
    "predictions_pd = predictions.select(\"Date\", \"prediction\").toPandas()\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(predictions_pd[\"Date\"], predictions_pd[\"prediction\"])\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Predicted Traffic Flow\")\n",
    "plt.title(\"Predicted Traffic Flow for Next 3 Hours\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+---+\n",
      "|Anomaly_3hr_Ahead|  0.0|1.0|\n",
      "+-----------------+-----+---+\n",
      "|              0.0|10421| 68|\n",
      "|              1.0|   35| 56|\n",
      "+-----------------+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SparkSession' object has no attribute 'setLogLevel'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[67], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetLogLevel\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDEBUG\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'SparkSession' object has no attribute 'setLogLevel'"
     ]
    }
   ],
   "source": [
    "spark.setLogLevel(\"DEBUG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 6178.0 failed 1 times, most recent failure: Lost task 0.0 in stage 6178.0 (TID 3910) (192.168.1.105 executor driver): org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:203)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.base/sun.nio.ch.NioSocketImpl.timedAccept(NioSocketImpl.java:701)\r\n\tat java.base/sun.nio.ch.NioSocketImpl.accept(NioSocketImpl.java:745)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:698)\r\n\tat java.base/java.net.ServerSocket.platformImplAccept(ServerSocket.java:663)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:639)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:585)\r\n\tat java.base/java.net.ServerSocket.accept(ServerSocket.java:543)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:190)\r\n\t... 17 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2393)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2414)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2433)\r\n\tat org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:181)\r\n\tat org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\nCaused by: org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:203)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\t... 1 more\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.base/sun.nio.ch.NioSocketImpl.timedAccept(NioSocketImpl.java:701)\r\n\tat java.base/sun.nio.ch.NioSocketImpl.accept(NioSocketImpl.java:745)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:698)\r\n\tat java.base/java.net.ServerSocket.platformImplAccept(ServerSocket.java:663)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:639)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:585)\r\n\tat java.base/java.net.ServerSocket.accept(ServerSocket.java:543)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:190)\r\n\t... 17 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[68], line 11\u001b[0m\n\u001b[0;32m      6\u001b[0m predictions \u001b[38;5;241m=\u001b[39m predictions\u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnomaly_3hr_Ahead\u001b[39m\u001b[38;5;124m\"\u001b[39m, col(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnomaly_3hr_Ahead\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mcast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdouble\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m      8\u001b[0m prediction_and_labels \u001b[38;5;241m=\u001b[39m predictions\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnomaly_3hr_Ahead\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;241m.\u001b[39mrdd\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m row: (\u001b[38;5;28mfloat\u001b[39m(row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m\"\u001b[39m]), \u001b[38;5;28mfloat\u001b[39m(row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnomaly_3hr_Ahead\u001b[39m\u001b[38;5;124m\"\u001b[39m])))\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mprediction_and_labels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m)  \u001b[38;5;66;03m# Fetch 5 rows\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\anaconda3\\envs\\anomaly_detect\\lib\\site-packages\\pyspark\\rdd.py:2855\u001b[0m, in \u001b[0;36mRDD.take\u001b[1;34m(self, num)\u001b[0m\n\u001b[0;32m   2852\u001b[0m         taken \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   2854\u001b[0m p \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(partsScanned, \u001b[38;5;28mmin\u001b[39m(partsScanned \u001b[38;5;241m+\u001b[39m numPartsToTry, totalParts))\n\u001b[1;32m-> 2855\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunJob\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtakeUpToNumLeft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2857\u001b[0m items \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m res\n\u001b[0;32m   2858\u001b[0m partsScanned \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m numPartsToTry\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\anaconda3\\envs\\anomaly_detect\\lib\\site-packages\\pyspark\\context.py:2510\u001b[0m, in \u001b[0;36mSparkContext.runJob\u001b[1;34m(self, rdd, partitionFunc, partitions, allowLocal)\u001b[0m\n\u001b[0;32m   2508\u001b[0m mappedRDD \u001b[38;5;241m=\u001b[39m rdd\u001b[38;5;241m.\u001b[39mmapPartitions(partitionFunc)\n\u001b[0;32m   2509\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 2510\u001b[0m sock_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPythonRDD\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunJob\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmappedRDD\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jrdd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartitions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2511\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_load_from_socket(sock_info, mappedRDD\u001b[38;5;241m.\u001b[39m_jrdd_deserializer))\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\anaconda3\\envs\\anomaly_detect\\lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\anaconda3\\envs\\anomaly_detect\\lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\anaconda3\\envs\\anomaly_detect\\lib\\site-packages\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 6178.0 failed 1 times, most recent failure: Lost task 0.0 in stage 6178.0 (TID 3910) (192.168.1.105 executor driver): org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:203)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.base/sun.nio.ch.NioSocketImpl.timedAccept(NioSocketImpl.java:701)\r\n\tat java.base/sun.nio.ch.NioSocketImpl.accept(NioSocketImpl.java:745)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:698)\r\n\tat java.base/java.net.ServerSocket.platformImplAccept(ServerSocket.java:663)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:639)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:585)\r\n\tat java.base/java.net.ServerSocket.accept(ServerSocket.java:543)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:190)\r\n\t... 17 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2393)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2414)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2433)\r\n\tat org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:181)\r\n\tat org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\nCaused by: org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:203)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\t... 1 more\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.base/sun.nio.ch.NioSocketImpl.timedAccept(NioSocketImpl.java:701)\r\n\tat java.base/sun.nio.ch.NioSocketImpl.accept(NioSocketImpl.java:745)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:698)\r\n\tat java.base/java.net.ServerSocket.platformImplAccept(ServerSocket.java:663)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:639)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:585)\r\n\tat java.base/java.net.ServerSocket.accept(ServerSocket.java:543)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:190)\r\n\t... 17 more\r\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "predictions = predictions.na.drop(subset=[\"prediction\", \"Anomaly_3hr_Ahead\"])\n",
    "predictions = predictions.withColumn(\"prediction\", col(\"prediction\").cast(\"double\"))\n",
    "predictions = predictions.withColumn(\"Anomaly_3hr_Ahead\", col(\"Anomaly_3hr_Ahead\").cast(\"double\"))\n",
    "\n",
    "prediction_and_labels = predictions.select(\"prediction\", \"Anomaly_3hr_Ahead\") \\\n",
    "    .rdd.map(lambda row: (float(row[\"prediction\"]), float(row[\"Anomaly_3hr_Ahead\"])))\n",
    "\n",
    "print(prediction_and_labels.take(5))  # Fetch 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows after dropping nulls: 10580\n",
      "root\n",
      " |-- Date: timestamp (nullable = true)\n",
      " |-- BGT North of NE 70th Total: double (nullable = false)\n",
      " |-- Ped South: double (nullable = false)\n",
      " |-- Ped North: double (nullable = false)\n",
      " |-- Bike North: double (nullable = false)\n",
      " |-- Bike South: double (nullable = false)\n",
      " |-- Anomaly: integer (nullable = false)\n",
      " |-- Anomaly_3hr_Ahead: double (nullable = true)\n",
      " |-- Lag_1_day: double (nullable = false)\n",
      " |-- Lag_2_day: double (nullable = false)\n",
      " |-- Lag_3_day: double (nullable = false)\n",
      " |-- Rolling_Mean_3H: double (nullable = false)\n",
      " |-- Rolling_Std_3H: double (nullable = false)\n",
      " |-- Bike_Ped_Ratio: double (nullable = false)\n",
      " |-- class_weight: double (nullable = false)\n",
      " |-- features1: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 6169.0 failed 1 times, most recent failure: Lost task 0.0 in stage 6169.0 (TID 3904) (192.168.1.105 executor driver): org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:203)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.base/sun.nio.ch.NioSocketImpl.timedAccept(NioSocketImpl.java:701)\r\n\tat java.base/sun.nio.ch.NioSocketImpl.accept(NioSocketImpl.java:745)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:698)\r\n\tat java.base/java.net.ServerSocket.platformImplAccept(ServerSocket.java:663)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:639)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:585)\r\n\tat java.base/java.net.ServerSocket.accept(ServerSocket.java:543)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:190)\r\n\t... 17 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2393)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2414)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2433)\r\n\tat org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:181)\r\n\tat org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\nCaused by: org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:203)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\t... 1 more\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.base/sun.nio.ch.NioSocketImpl.timedAccept(NioSocketImpl.java:701)\r\n\tat java.base/sun.nio.ch.NioSocketImpl.accept(NioSocketImpl.java:745)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:698)\r\n\tat java.base/java.net.ServerSocket.platformImplAccept(ServerSocket.java:663)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:639)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:585)\r\n\tat java.base/java.net.ServerSocket.accept(ServerSocket.java:543)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:190)\r\n\t... 17 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m prediction_and_labels \u001b[38;5;241m=\u001b[39m predictions\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnomaly_3hr_Ahead\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;241m.\u001b[39mrdd\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m row: (\u001b[38;5;28mfloat\u001b[39m(row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m\"\u001b[39m]), \u001b[38;5;28mfloat\u001b[39m(row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnomaly_3hr_Ahead\u001b[39m\u001b[38;5;124m\"\u001b[39m])))\n\u001b[0;32m     14\u001b[0m predictions\u001b[38;5;241m.\u001b[39mprintSchema()\n\u001b[1;32m---> 15\u001b[0m \u001b[43mprediction_and_labels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Fetch 5 rows\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(prediction_and_labels)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prediction_and_labels\u001b[38;5;241m.\u001b[39mcount() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\anaconda3\\envs\\anomaly_detect\\lib\\site-packages\\pyspark\\rdd.py:2855\u001b[0m, in \u001b[0;36mRDD.take\u001b[1;34m(self, num)\u001b[0m\n\u001b[0;32m   2852\u001b[0m         taken \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   2854\u001b[0m p \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(partsScanned, \u001b[38;5;28mmin\u001b[39m(partsScanned \u001b[38;5;241m+\u001b[39m numPartsToTry, totalParts))\n\u001b[1;32m-> 2855\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunJob\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtakeUpToNumLeft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2857\u001b[0m items \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m res\n\u001b[0;32m   2858\u001b[0m partsScanned \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m numPartsToTry\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\anaconda3\\envs\\anomaly_detect\\lib\\site-packages\\pyspark\\context.py:2510\u001b[0m, in \u001b[0;36mSparkContext.runJob\u001b[1;34m(self, rdd, partitionFunc, partitions, allowLocal)\u001b[0m\n\u001b[0;32m   2508\u001b[0m mappedRDD \u001b[38;5;241m=\u001b[39m rdd\u001b[38;5;241m.\u001b[39mmapPartitions(partitionFunc)\n\u001b[0;32m   2509\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 2510\u001b[0m sock_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPythonRDD\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunJob\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmappedRDD\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jrdd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartitions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2511\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_load_from_socket(sock_info, mappedRDD\u001b[38;5;241m.\u001b[39m_jrdd_deserializer))\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\anaconda3\\envs\\anomaly_detect\\lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\anaconda3\\envs\\anomaly_detect\\lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\anaconda3\\envs\\anomaly_detect\\lib\\site-packages\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 6169.0 failed 1 times, most recent failure: Lost task 0.0 in stage 6169.0 (TID 3904) (192.168.1.105 executor driver): org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:203)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.base/sun.nio.ch.NioSocketImpl.timedAccept(NioSocketImpl.java:701)\r\n\tat java.base/sun.nio.ch.NioSocketImpl.accept(NioSocketImpl.java:745)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:698)\r\n\tat java.base/java.net.ServerSocket.platformImplAccept(ServerSocket.java:663)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:639)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:585)\r\n\tat java.base/java.net.ServerSocket.accept(ServerSocket.java:543)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:190)\r\n\t... 17 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2393)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2414)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2433)\r\n\tat org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:181)\r\n\tat org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\nCaused by: org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:203)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\t... 1 more\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.base/sun.nio.ch.NioSocketImpl.timedAccept(NioSocketImpl.java:701)\r\n\tat java.base/sun.nio.ch.NioSocketImpl.accept(NioSocketImpl.java:745)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:698)\r\n\tat java.base/java.net.ServerSocket.platformImplAccept(ServerSocket.java:663)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:639)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:585)\r\n\tat java.base/java.net.ServerSocket.accept(ServerSocket.java:543)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:190)\r\n\t... 17 more\r\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "predictions = predictions.na.drop(subset=[\"prediction\", \"Anomaly_3hr_Ahead\"])\n",
    "predictions = predictions.na.drop(subset=[\"prediction\", \"Anomaly_3hr_Ahead\"])\n",
    "print(f\"Total rows after dropping nulls: {predictions.count()}\")\n",
    "\n",
    "predictions = predictions.withColumn(\"prediction\", col(\"prediction\").cast(\"double\"))\n",
    "predictions = predictions.withColumn(\"Anomaly_3hr_Ahead\", col(\"Anomaly_3hr_Ahead\").cast(\"double\"))\n",
    "# predictions = predictions.withColumn(\"\")\n",
    "# Convert predictions to RDD format for MulticlassMetrics\n",
    "prediction_and_labels = predictions.select(\"prediction\", \"Anomaly_3hr_Ahead\") \\\n",
    "    .rdd.map(lambda row: (float(row[\"prediction\"]), float(row[\"Anomaly_3hr_Ahead\"])))\n",
    "predictions.printSchema()\n",
    "prediction_and_labels.map(lambda x: x).take(5)  # Fetch 5 rows\n",
    "\n",
    "print(prediction_and_labels)\n",
    "if prediction_and_labels.count() == 0:\n",
    "    print(\"RDD is empty! Check your predictions DataFrame.\")\n",
    "else:\n",
    "    print(f\"RDD contains {prediction_and_labels.count()} records.\")\n",
    "\n",
    "print(f\"Total rows in predictions: {predictions.count()}\")\n",
    "print(f\"Total rows in RDD: {prediction_and_labels.count()}\")\n",
    "\n",
    "print(prediction_and_labels.count())  # Should be greater than 0\n",
    "print(prediction_and_labels.take(5))  # Inspect first 5 rows\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "metrics = MulticlassMetrics(prediction_and_labels)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(metrics.confusionMatrix().toArray())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(\"target_3hr\", axis=1)\n",
    "y = df[\"target_3hr\"]\n",
    "\n",
    "# Impute missing values with the mean (or use \"median\", \"most_frequent\", etc.)\n",
    "imputer = SimpleImputer(strategy=\"mean\")\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_imputed, y)\n",
    "\n",
    "# Combine back into DataFrame\n",
    "resampled_df = pd.concat([\n",
    "    pd.DataFrame(X_resampled, columns=X.columns),\n",
    "    pd.Series(y_resampled, name=\"target_3hr\")\n",
    "], axis=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anomaly_detect",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
