{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seasonal Decomposition\n",
    "\n",
    "result = seasonal_decompose(df['Ped South'],model='addictive', period = 365)\n",
    "result.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # First, inspect the spike by visualizing it\n",
    "# df['Ped South'].loc['2018-01-01':'2018-12-31'].plot()\n",
    "\n",
    "# # If it's an anomaly (after investigation), you can either:\n",
    "# # 1. Correct the values (set to NaN or replace with nearby values)\n",
    "# df.loc['2018-01-01':'2018-12-31', 'Ped South'] = np.nan  # Replace with NaN\n",
    "# # or \n",
    "# # 2. Remove the period (drop the rows)A\n",
    "# df = df[df.index.year != 2018]  # Remove 2018 data entirely\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[['Ped North Z', 'Ped South Z', 'Bike North Z', 'Bike South Z']] = df[['Ped North', 'Ped South', 'Bike North', 'Bike South']].apply(zscore)\n",
    "# plt.figure(figsize=(12,6))\n",
    "# plt.plot(df.index, df['Ped North Z'],label = 'Ped North Z', color = 'green')\n",
    "# plt.plot(df.index, df['Ped South Z'],label = 'Ped South Z', color = 'red')\n",
    "# plt.plot(df.index, df['Bike North Z'],label = 'Bike North Z', color = 'yellow')\n",
    "# plt.plot(df.index, df['Bike South Z'],label = 'Bike South Z', color = 'blue')\n",
    "# plt.axhline(y= 3, color = 'red', linestyle = '--', label = 'Threshold')\n",
    "# plt.axhline(y=3, color = 'red', linestyle = '--')\n",
    "# plt.title('Z-score of pedestrian traffic (ped south) over time')\n",
    "# plt.xlabel('Date')\n",
    "# plt.ylabel('z-score')\n",
    "# plt.legend()\n",
    "# plt.xticks(rotation = 45)\n",
    "# plt.show()\n",
    "\n",
    "# anomalies = df[df['Ped North Z'].abs()>5]\n",
    "# print(anomalies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Separate features and target\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_3hr\u001b[39m\u001b[38;5;124m\"\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      7\u001b[0m y \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_3hr\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# model = XGBClassifier(scale_pos_weight=100, use_label_encoder=False, eval_metric=\"logloss\")\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Impute missing values with the mean (or use \"median\", \"most_frequent\", etc.)\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "#SMOTE process\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(\"target_3hr\", axis=1)\n",
    "y = df[\"target_3hr\"]\n",
    "\n",
    "\n",
    "# model = XGBClassifier(scale_pos_weight=100, use_label_encoder=False, eval_metric=\"logloss\")\n",
    "# Impute missing values with the mean (or use \"median\", \"most_frequent\", etc.)\n",
    "imputer = SimpleImputer(strategy=\"mean\")\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_imputed, y)\n",
    "\n",
    "# Combine back into DataFrame\n",
    "resampled_df = pd.concat([\n",
    "    pd.DataFrame(X_resampled, columns=X.columns),\n",
    "    pd.Series(y_resampled, name=\"target_3hr\")\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balanced dataset \n",
    "# Step 1: Separate majority and minority classes\n",
    "majority_class = df[df[\"target_3hr\"] == 0]\n",
    "minority_class = df[df[\"target_3hr\"] == 1]\n",
    "\n",
    "# Step 2: Sample only if population is large enough\n",
    "n_samples = min(len(majority_class), len(minority_class))\n",
    "majority_class_sampled = majority_class.sample(n=n_samples, random_state=42)\n",
    "minority_class_sampled = minority_class.sample(n=n_samples, random_state=42)\n",
    "\n",
    "# Step 3: Combine both\n",
    "balanced_df = pd.concat([majority_class_sampled, minority_class_sampled])\n",
    "\n",
    "# Step 4: Shuffle\n",
    "balanced_df = balanced_df.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features =  ['lag_1hr',\t'lag_2hr','lag_3hr']\n",
    "# Step 3: Split into Features and Target\n",
    "X = balanced_df.drop(\"target_3hr\", axis=1)\n",
    "y = balanced_df[\"target_3hr\"]\n",
    "\n",
    "#split the dataset into training and test dataset\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size = 0.3, random_state = 42) \n",
    "model = RandomForestClassifier(class_weight='balanced',n_estimators=50,random_state= 42)\n",
    "# model = XGBClassifier(scale_pos_weight=100, use_label_encoder=False, eval_metric=\"logloss\")\n",
    "\n",
    "model.fit(X_train,Y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "\n",
    "\n",
    "# Get prediction probabilities\n",
    "y_probs = model.predict_proba(X_test)[:, 1]  # Get probability of class 1\n",
    "\n",
    "# Adjust threshold to increase recall\n",
    "threshold = 0.3  # Lower threshold to catch more anomalies\n",
    "y_pred_adjusted = (y_probs >= threshold).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(Y_test, y_pred_adjusted)\n",
    "print(f\"Model Accuracy: {accuracy:.2f}\")\n",
    "print(classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df['residual'] = df['actual'] - df['predicted']\n",
    "\n",
    "# # Flag residuals as anomalies if they exceed 3 standard deviations\n",
    "# df['anomaly'] = df['residual'].apply(lambda x: 1 if abs(x) > 3 * df['residual'].std() else 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### remaining features (rolling mean 3h, rolling std 3h,rolling 7d avg,month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from typing import Union\n",
    "# from fastapi import FastAPI\n",
    "\n",
    "# app = FastAPI()\n",
    "\n",
    "# # @app.get(\"/\")\n",
    "# def root():\n",
    "#     print(\"hello this is inferenece model\")\n",
    "\n",
    "# @app.get(\"/data\")\n",
    "# def get_data():\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anomaly_detect",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
